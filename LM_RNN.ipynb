{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8476e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\",delimiter='\\t')\n",
    "test = pd.read_csv(\"test.csv\",delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "105b128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>code_news</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/fa/news/6276899/اسفراین-جولانگاه-مقدونیان-تصا...</td>\n",
       "      <td>اسفراین؛ جولانگاه مقدونیان + تصاویر</td>\n",
       "      <td>کد خبر: ۶۲۷۶۸۹۹</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۱ مهر ۱۳۹۶ - ۰۷:۰۴</td>\n",
       "      <td>به گزارش خبرنگار حوزه میراث و گردشگری گروه فر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/fa/news/4626291/اجرای-قطعات-سلام-آقا-بدون-انگ...</td>\n",
       "      <td>اجرای قطعات \"سلام آقا\" بدون انگیزه مالی و با ا...</td>\n",
       "      <td>کد خبر: ۴۶۲۶۲۹۱</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۱۹ آبان ۱۳۹۲ - ۱۰:۰۰</td>\n",
       "      <td>به گزارش حوزه موسیقی باشگاه خبرنگاران، مهدی ی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/fa/news/4632846/حکایت-سیاریحون-از-نهضت-میرزا-...</td>\n",
       "      <td>حکایت \"سیاریحون\" از نهضت میرزا کوچک خان جنگلی ...</td>\n",
       "      <td>کد خبر: ۴۶۳۲۸۴۶</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۵ آبان ۱۳۹۲ - ۱۳:۴۵</td>\n",
       "      <td>به گزارش حوزه تئاتر باشگاه خبرنگاران به نقل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/fa/news/5058438/گفتگو-با-کارگردان-سریال-شهید-...</td>\n",
       "      <td>گفتگو با کارگردان سریال شهید مدرس/قدرت بیان فو...</td>\n",
       "      <td>کد خبر: ۵۰۵۸۴۳۸</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۱۰ آذر ۱۳۹۳ - ۱۰:۵۴</td>\n",
       "      <td>به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/fa/news/6668241/گزارش-تصویری-مراسم-عزاداری-شب...</td>\n",
       "      <td>گزارش تصویری مراسم عزاداری شب ششم محرم ۹۷/ حضو...</td>\n",
       "      <td>کد خبر: ۶۶۶۸۲۴۱</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۵ شهريور ۱۳۹۷ - ۱۰:۳۵</td>\n",
       "      <td>به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117187</th>\n",
       "      <td>/fa/news/5987093/پرسپولیس-ایران-الهلال-عربستان...</td>\n",
       "      <td>پرسپولیس ایران _ الهلال عربستان/ پرتماشاگرترین...</td>\n",
       "      <td>کد خبر: ۵۹۸۷۰۹۳</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۳ اسفند ۱۳۹۵ - ۱۰:۰۰</td>\n",
       "      <td>به گزارش\\r\\nخبرنگار حوزه فوتبال و فوتسال گروه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117188</th>\n",
       "      <td>/fa/news/4800268/شیاپ-چانگ-انتخابی-برای-پومسه-...</td>\n",
       "      <td>شیاپ چانگ انتخابی برای پومسه رو ها</td>\n",
       "      <td>کد خبر: ۴۸۰۰۲۶۸</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۲۲ فروردين ۱۳۹۳ - ۱۳:۳۷</td>\n",
       "      <td>به گزارش خبرنگار\\r\\nورزشی باشگاه خبرنگاران؛ ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117189</th>\n",
       "      <td>/fa/news/5470894/منچستریونایتد-مذاکره-با-گوارد...</td>\n",
       "      <td>منچستریونایتد مذاکره با گواردیولا را تکذیب کرد</td>\n",
       "      <td>کد خبر: ۵۴۷۰۸۹۴</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۳ بهمن ۱۳۹۴ - ۰۴:۱۶</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117190</th>\n",
       "      <td>/fa/news/6637446/نویمایر-آلمانی-آری-جپاروف-ازب...</td>\n",
       "      <td>نویمایر آلمانی آری جپاروف ازبک خیر/منطق قراردا...</td>\n",
       "      <td>کد خبر: ۶۶۳۷۴۴۶</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۸ مهر ۱۳۹۷ - ۱۴:۳۳</td>\n",
       "      <td>به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117191</th>\n",
       "      <td>/fa/news/5727671/برنامه-روز-هفتم-مسابقات-المپی...</td>\n",
       "      <td>برنامه روز هفتم مسابقات المپیک ریو</td>\n",
       "      <td>کد خبر: ۵۷۲۷۶۷۱</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۱۹ مرداد ۱۳۹۵ - ۱۰:۱۲</td>\n",
       "      <td>*برنامه رقابت های  ملی پوشان کاروان ایران : گ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link  \\\n",
       "0       /fa/news/6276899/اسفراین-جولانگاه-مقدونیان-تصا...   \n",
       "1       /fa/news/4626291/اجرای-قطعات-سلام-آقا-بدون-انگ...   \n",
       "2       /fa/news/4632846/حکایت-سیاریحون-از-نهضت-میرزا-...   \n",
       "3       /fa/news/5058438/گفتگو-با-کارگردان-سریال-شهید-...   \n",
       "4       /fa/news/6668241/گزارش-تصویری-مراسم-عزاداری-شب...   \n",
       "...                                                   ...   \n",
       "117187  /fa/news/5987093/پرسپولیس-ایران-الهلال-عربستان...   \n",
       "117188  /fa/news/4800268/شیاپ-چانگ-انتخابی-برای-پومسه-...   \n",
       "117189  /fa/news/5470894/منچستریونایتد-مذاکره-با-گوارد...   \n",
       "117190  /fa/news/6637446/نویمایر-آلمانی-آری-جپاروف-ازب...   \n",
       "117191  /fa/news/5727671/برنامه-روز-هفتم-مسابقات-المپی...   \n",
       "\n",
       "                                                    title        code_news  \\\n",
       "0                     اسفراین؛ جولانگاه مقدونیان + تصاویر  کد خبر: ۶۲۷۶۸۹۹   \n",
       "1       اجرای قطعات \"سلام آقا\" بدون انگیزه مالی و با ا...  کد خبر: ۴۶۲۶۲۹۱   \n",
       "2       حکایت \"سیاریحون\" از نهضت میرزا کوچک خان جنگلی ...  کد خبر: ۴۶۳۲۸۴۶   \n",
       "3       گفتگو با کارگردان سریال شهید مدرس/قدرت بیان فو...  کد خبر: ۵۰۵۸۴۳۸   \n",
       "4       گزارش تصویری مراسم عزاداری شب ششم محرم ۹۷/ حضو...  کد خبر: ۶۶۶۸۲۴۱   \n",
       "...                                                   ...              ...   \n",
       "117187  پرسپولیس ایران _ الهلال عربستان/ پرتماشاگرترین...  کد خبر: ۵۹۸۷۰۹۳   \n",
       "117188                 شیاپ چانگ انتخابی برای پومسه رو ها  کد خبر: ۴۸۰۰۲۶۸   \n",
       "117189     منچستریونایتد مذاکره با گواردیولا را تکذیب کرد  کد خبر: ۵۴۷۰۸۹۴   \n",
       "117190  نویمایر آلمانی آری جپاروف ازبک خیر/منطق قراردا...  کد خبر: ۶۶۳۷۴۴۶   \n",
       "117191                 برنامه روز هفتم مسابقات المپیک ریو  کد خبر: ۵۷۲۷۶۷۱   \n",
       "\n",
       "           category                                   date  \\\n",
       "0       فرهنگی هنری      تاریخ انتشار: ۲۱ مهر ۱۳۹۶ - ۰۷:۰۴   \n",
       "1       فرهنگی هنری     تاریخ انتشار: ۱۹ آبان ۱۳۹۲ - ۱۰:۰۰   \n",
       "2       فرهنگی هنری     تاریخ انتشار: ۲۵ آبان ۱۳۹۲ - ۱۳:۴۵   \n",
       "3       فرهنگی هنری      تاریخ انتشار: ۱۰ آذر ۱۳۹۳ - ۱۰:۵۴   \n",
       "4       فرهنگی هنری   تاریخ انتشار: ۲۵ شهريور ۱۳۹۷ - ۱۰:۳۵   \n",
       "...             ...                                    ...   \n",
       "117187        ورزشی    تاریخ انتشار: ۰۳ اسفند ۱۳۹۵ - ۱۰:۰۰   \n",
       "117188        ورزشی  تاریخ انتشار: ۲۲ فروردين ۱۳۹۳ - ۱۳:۳۷   \n",
       "117189        ورزشی     تاریخ انتشار: ۰۳ بهمن ۱۳۹۴ - ۰۴:۱۶   \n",
       "117190        ورزشی      تاریخ انتشار: ۰۸ مهر ۱۳۹۷ - ۱۴:۳۳   \n",
       "117191        ورزشی    تاریخ انتشار: ۱۹ مرداد ۱۳۹۵ - ۱۰:۱۲   \n",
       "\n",
       "                                                     text  \n",
       "0        به گزارش خبرنگار حوزه میراث و گردشگری گروه فر...  \n",
       "1        به گزارش حوزه موسیقی باشگاه خبرنگاران، مهدی ی...  \n",
       "2        به گزارش حوزه تئاتر باشگاه خبرنگاران به نقل ا...  \n",
       "3        به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگا...  \n",
       "4        به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگا...  \n",
       "...                                                   ...  \n",
       "117187   به گزارش\\r\\nخبرنگار حوزه فوتبال و فوتسال گروه...  \n",
       "117188   به گزارش خبرنگار\\r\\nورزشی باشگاه خبرنگاران؛ ر...  \n",
       "117189                                                NaN  \n",
       "117190   به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی ...  \n",
       "117191   *برنامه رقابت های  ملی پوشان کاروان ایران : گ...  \n",
       "\n",
       "[117192 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c28d635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117192, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bbc5880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21104, 6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "481df251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8e1bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.cleaned_data=self.clean(self.data)\n",
    "        self.dict_chars,self.unique_chars,self.all_chars=self.count_chars(self.cleaned_data)\n",
    "        self.char2index,self.index2char=self.tokenize()\n",
    "    def clean(self,data):\n",
    "        data.dropna(subset=['text'],inplace= True)\n",
    "        cleaned_data=[]\n",
    "        for i in data[\"text\"]:\n",
    "            st=re.sub(r\"[^۰-۹\\ژ\\ز\\ر\\ذ\\د\\خ\\ح\\چ\\ج\\ث\\ت\\ب\\پ\\ا\\.\\؟\\س\\ش\\ص\\ض\\ط\\ظ\\ع\\غ\\ف\\ق\\ک\\گ\\ل\\م\\ن\\و\\ه\\ی\\آ]\",\" \",i)\n",
    "            st=re.sub(r\"[۰-۹]+\",\"N\",st)\n",
    "            st=\"s\" + st + \"e\"\n",
    "            cleaned_data.append(st)\n",
    "        cleaned_data=pd.DataFrame({'text':cleaned_data})\n",
    "        return cleaned_data\n",
    "    def count_chars(self,cleaned_data):\n",
    "        chars=[]\n",
    "        for i in cleaned_data[\"text\"]:\n",
    "            for j in i:\n",
    "                chars.append(j)\n",
    "        count=Counter(chars)\n",
    "        unique_chars=len(count.keys())\n",
    "        all_chars=sum(count.values())\n",
    "        return count,unique_chars,all_chars\n",
    "    def tokenize(self):\n",
    "        list=[]\n",
    "        for key in self.dict_chars.keys():\n",
    "            list.append(key)\n",
    "        list2=[]\n",
    "        list3=[]\n",
    "        for i in range(len(list)):\n",
    "            list2.append((list[i],i))\n",
    "            list3.append((i,list[i]))\n",
    "        char2index=dict(list2)\n",
    "        index2char=dict(list3)\n",
    "        return char2index,index2char\n",
    "    def char_to_index(self,string):\n",
    "        list4=[]\n",
    "        for m in string:\n",
    "            if(m in self.char2index.keys()):\n",
    "                list4.append(self.char2index.get(m))\n",
    "            else:\n",
    "                list4.append(-1)\n",
    "        return list4\n",
    "    def index_to_char(self,numbers):\n",
    "        st=\"\"\n",
    "        for n in numbers:\n",
    "            if(n in self.index2char.keys()):\n",
    "                st=st+self.index2char.get(n)\n",
    "            else:\n",
    "                st=st+' '\n",
    "        return st         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e49e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "object1=DataPreprocessor(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b47f680c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>code_news</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/fa/news/6276899/اسفراین-جولانگاه-مقدونیان-تصا...</td>\n",
       "      <td>اسفراین؛ جولانگاه مقدونیان + تصاویر</td>\n",
       "      <td>کد خبر: ۶۲۷۶۸۹۹</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۱ مهر ۱۳۹۶ - ۰۷:۰۴</td>\n",
       "      <td>به گزارش خبرنگار حوزه میراث و گردشگری گروه فر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/fa/news/4626291/اجرای-قطعات-سلام-آقا-بدون-انگ...</td>\n",
       "      <td>اجرای قطعات \"سلام آقا\" بدون انگیزه مالی و با ا...</td>\n",
       "      <td>کد خبر: ۴۶۲۶۲۹۱</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۱۹ آبان ۱۳۹۲ - ۱۰:۰۰</td>\n",
       "      <td>به گزارش حوزه موسیقی باشگاه خبرنگاران، مهدی ی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/fa/news/4632846/حکایت-سیاریحون-از-نهضت-میرزا-...</td>\n",
       "      <td>حکایت \"سیاریحون\" از نهضت میرزا کوچک خان جنگلی ...</td>\n",
       "      <td>کد خبر: ۴۶۳۲۸۴۶</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۵ آبان ۱۳۹۲ - ۱۳:۴۵</td>\n",
       "      <td>به گزارش حوزه تئاتر باشگاه خبرنگاران به نقل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/fa/news/5058438/گفتگو-با-کارگردان-سریال-شهید-...</td>\n",
       "      <td>گفتگو با کارگردان سریال شهید مدرس/قدرت بیان فو...</td>\n",
       "      <td>کد خبر: ۵۰۵۸۴۳۸</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۱۰ آذر ۱۳۹۳ - ۱۰:۵۴</td>\n",
       "      <td>به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/fa/news/6668241/گزارش-تصویری-مراسم-عزاداری-شب...</td>\n",
       "      <td>گزارش تصویری مراسم عزاداری شب ششم محرم ۹۷/ حضو...</td>\n",
       "      <td>کد خبر: ۶۶۶۸۲۴۱</td>\n",
       "      <td>فرهنگی هنری</td>\n",
       "      <td>تاریخ انتشار: ۲۵ شهريور ۱۳۹۷ - ۱۰:۳۵</td>\n",
       "      <td>به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117182</th>\n",
       "      <td>/fa/news/6513525/منتخب-لحظات-برتر-اینیستا-فیلم\\n</td>\n",
       "      <td>منتخب لحظات برتر اینیستا + فیلم</td>\n",
       "      <td>کد خبر: ۶۵۱۳۵۲۵</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۵ ارديبهشت ۱۳۹۷ - ۲۱:۲۸</td>\n",
       "      <td>به گزارش گروه فیلم و صوت باشگاه خبرنگاران جوا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117187</th>\n",
       "      <td>/fa/news/5987093/پرسپولیس-ایران-الهلال-عربستان...</td>\n",
       "      <td>پرسپولیس ایران _ الهلال عربستان/ پرتماشاگرترین...</td>\n",
       "      <td>کد خبر: ۵۹۸۷۰۹۳</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۳ اسفند ۱۳۹۵ - ۱۰:۰۰</td>\n",
       "      <td>به گزارش\\r\\nخبرنگار حوزه فوتبال و فوتسال گروه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117188</th>\n",
       "      <td>/fa/news/4800268/شیاپ-چانگ-انتخابی-برای-پومسه-...</td>\n",
       "      <td>شیاپ چانگ انتخابی برای پومسه رو ها</td>\n",
       "      <td>کد خبر: ۴۸۰۰۲۶۸</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۲۲ فروردين ۱۳۹۳ - ۱۳:۳۷</td>\n",
       "      <td>به گزارش خبرنگار\\r\\nورزشی باشگاه خبرنگاران؛ ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117190</th>\n",
       "      <td>/fa/news/6637446/نویمایر-آلمانی-آری-جپاروف-ازب...</td>\n",
       "      <td>نویمایر آلمانی آری جپاروف ازبک خیر/منطق قراردا...</td>\n",
       "      <td>کد خبر: ۶۶۳۷۴۴۶</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۰۸ مهر ۱۳۹۷ - ۱۴:۳۳</td>\n",
       "      <td>به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117191</th>\n",
       "      <td>/fa/news/5727671/برنامه-روز-هفتم-مسابقات-المپی...</td>\n",
       "      <td>برنامه روز هفتم مسابقات المپیک ریو</td>\n",
       "      <td>کد خبر: ۵۷۲۷۶۷۱</td>\n",
       "      <td>ورزشی</td>\n",
       "      <td>تاریخ انتشار: ۱۹ مرداد ۱۳۹۵ - ۱۰:۱۲</td>\n",
       "      <td>*برنامه رقابت های  ملی پوشان کاروان ایران : گ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97030 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link  \\\n",
       "0       /fa/news/6276899/اسفراین-جولانگاه-مقدونیان-تصا...   \n",
       "1       /fa/news/4626291/اجرای-قطعات-سلام-آقا-بدون-انگ...   \n",
       "2       /fa/news/4632846/حکایت-سیاریحون-از-نهضت-میرزا-...   \n",
       "3       /fa/news/5058438/گفتگو-با-کارگردان-سریال-شهید-...   \n",
       "4       /fa/news/6668241/گزارش-تصویری-مراسم-عزاداری-شب...   \n",
       "...                                                   ...   \n",
       "117182   /fa/news/6513525/منتخب-لحظات-برتر-اینیستا-فیلم\\n   \n",
       "117187  /fa/news/5987093/پرسپولیس-ایران-الهلال-عربستان...   \n",
       "117188  /fa/news/4800268/شیاپ-چانگ-انتخابی-برای-پومسه-...   \n",
       "117190  /fa/news/6637446/نویمایر-آلمانی-آری-جپاروف-ازب...   \n",
       "117191  /fa/news/5727671/برنامه-روز-هفتم-مسابقات-المپی...   \n",
       "\n",
       "                                                    title        code_news  \\\n",
       "0                     اسفراین؛ جولانگاه مقدونیان + تصاویر  کد خبر: ۶۲۷۶۸۹۹   \n",
       "1       اجرای قطعات \"سلام آقا\" بدون انگیزه مالی و با ا...  کد خبر: ۴۶۲۶۲۹۱   \n",
       "2       حکایت \"سیاریحون\" از نهضت میرزا کوچک خان جنگلی ...  کد خبر: ۴۶۳۲۸۴۶   \n",
       "3       گفتگو با کارگردان سریال شهید مدرس/قدرت بیان فو...  کد خبر: ۵۰۵۸۴۳۸   \n",
       "4       گزارش تصویری مراسم عزاداری شب ششم محرم ۹۷/ حضو...  کد خبر: ۶۶۶۸۲۴۱   \n",
       "...                                                   ...              ...   \n",
       "117182                    منتخب لحظات برتر اینیستا + فیلم  کد خبر: ۶۵۱۳۵۲۵   \n",
       "117187  پرسپولیس ایران _ الهلال عربستان/ پرتماشاگرترین...  کد خبر: ۵۹۸۷۰۹۳   \n",
       "117188                 شیاپ چانگ انتخابی برای پومسه رو ها  کد خبر: ۴۸۰۰۲۶۸   \n",
       "117190  نویمایر آلمانی آری جپاروف ازبک خیر/منطق قراردا...  کد خبر: ۶۶۳۷۴۴۶   \n",
       "117191                 برنامه روز هفتم مسابقات المپیک ریو  کد خبر: ۵۷۲۷۶۷۱   \n",
       "\n",
       "           category                                    date  \\\n",
       "0       فرهنگی هنری       تاریخ انتشار: ۲۱ مهر ۱۳۹۶ - ۰۷:۰۴   \n",
       "1       فرهنگی هنری      تاریخ انتشار: ۱۹ آبان ۱۳۹۲ - ۱۰:۰۰   \n",
       "2       فرهنگی هنری      تاریخ انتشار: ۲۵ آبان ۱۳۹۲ - ۱۳:۴۵   \n",
       "3       فرهنگی هنری       تاریخ انتشار: ۱۰ آذر ۱۳۹۳ - ۱۰:۵۴   \n",
       "4       فرهنگی هنری    تاریخ انتشار: ۲۵ شهريور ۱۳۹۷ - ۱۰:۳۵   \n",
       "...             ...                                     ...   \n",
       "117182        ورزشی  تاریخ انتشار: ۰۵ ارديبهشت ۱۳۹۷ - ۲۱:۲۸   \n",
       "117187        ورزشی     تاریخ انتشار: ۰۳ اسفند ۱۳۹۵ - ۱۰:۰۰   \n",
       "117188        ورزشی   تاریخ انتشار: ۲۲ فروردين ۱۳۹۳ - ۱۳:۳۷   \n",
       "117190        ورزشی       تاریخ انتشار: ۰۸ مهر ۱۳۹۷ - ۱۴:۳۳   \n",
       "117191        ورزشی     تاریخ انتشار: ۱۹ مرداد ۱۳۹۵ - ۱۰:۱۲   \n",
       "\n",
       "                                                     text  \n",
       "0        به گزارش خبرنگار حوزه میراث و گردشگری گروه فر...  \n",
       "1        به گزارش حوزه موسیقی باشگاه خبرنگاران، مهدی ی...  \n",
       "2        به گزارش حوزه تئاتر باشگاه خبرنگاران به نقل ا...  \n",
       "3        به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگا...  \n",
       "4        به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگا...  \n",
       "...                                                   ...  \n",
       "117182   به گزارش گروه فیلم و صوت باشگاه خبرنگاران جوا...  \n",
       "117187   به گزارش\\r\\nخبرنگار حوزه فوتبال و فوتسال گروه...  \n",
       "117188   به گزارش خبرنگار\\r\\nورزشی باشگاه خبرنگاران؛ ر...  \n",
       "117190   به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی ...  \n",
       "117191   *برنامه رقابت های  ملی پوشان کاروان ایران : گ...  \n",
       "\n",
       "[97030 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a90cbff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s به گزارش خبرنگار حوزه میراث و گردشگری گروه ف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s به گزارش حوزه موسیقی باشگاه خبرنگاران  مهدی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s به گزارش حوزه ت اتر باشگاه خبرنگاران به نقل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97025</th>\n",
       "      <td>s به گزارش گروه فیلم و صوت باشگاه خبرنگاران جو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97026</th>\n",
       "      <td>s به گزارش  خبرنگار حوزه فوتبال و فوتسال گروه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97027</th>\n",
       "      <td>s به گزارش خبرنگار  ورزشی باشگاه خبرنگاران  رق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97028</th>\n",
       "      <td>s به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97029</th>\n",
       "      <td>s  برنامه رقابت های  ملی پوشان کاروان ایران   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97030 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      s به گزارش خبرنگار حوزه میراث و گردشگری گروه ف...\n",
       "1      s به گزارش حوزه موسیقی باشگاه خبرنگاران  مهدی ...\n",
       "2      s به گزارش حوزه ت اتر باشگاه خبرنگاران به نقل ...\n",
       "3      s به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگ...\n",
       "4      s به گزارش خبرنگار تکیه حسینی گروه فرهنگی باشگ...\n",
       "...                                                  ...\n",
       "97025  s به گزارش گروه فیلم و صوت باشگاه خبرنگاران جو...\n",
       "97026  s به گزارش  خبرنگار حوزه فوتبال و فوتسال گروه ...\n",
       "97027  s به گزارش خبرنگار  ورزشی باشگاه خبرنگاران  رق...\n",
       "97028  s به گزارش  خبرنگار فوتبال و فوتسال گروه ورزشی...\n",
       "97029  s  برنامه رقابت های  ملی پوشان کاروان ایران   ...\n",
       "\n",
       "[97030 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data=object1.cleaned_data\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ec7267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=cleaned_data[\"text\"].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f0470bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s به گزارش خبرنگار حوزه میراث و گردشگری گروه فرهنگی باشگاه خبرنگاران جوان  محمد حسن خان اعتماد السلطنه به نقل از برخی منابع  اسفراین  را چمن کالپوش دانسته است. چمن کالپوش بر اساس آنچه در اعتقادات اهال'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ef65646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'s': 97030,\n",
       "         ' ': 47443628,\n",
       "         'ب': 5560834,\n",
       "         'ه': 7812715,\n",
       "         'گ': 1941309,\n",
       "         'ز': 2755953,\n",
       "         'ا': 19294844,\n",
       "         'ر': 11221534,\n",
       "         'ش': 3258093,\n",
       "         'خ': 1596153,\n",
       "         'ن': 8749660,\n",
       "         'ح': 1256529,\n",
       "         'و': 7352556,\n",
       "         'م': 7149615,\n",
       "         'ی': 10751361,\n",
       "         'ث': 165995,\n",
       "         'د': 8605850,\n",
       "         'ف': 1803107,\n",
       "         'ج': 1406612,\n",
       "         'س': 3962124,\n",
       "         'ع': 1595400,\n",
       "         'ت': 6155048,\n",
       "         'ل': 3480712,\n",
       "         'ط': 639410,\n",
       "         'ق': 1419533,\n",
       "         'چ': 366094,\n",
       "         'ک': 3087117,\n",
       "         'پ': 862128,\n",
       "         '.': 1040558,\n",
       "         'آ': 800641,\n",
       "         'غ': 235077,\n",
       "         'N': 115757,\n",
       "         'ذ': 230921,\n",
       "         'ظ': 265260,\n",
       "         'ص': 814177,\n",
       "         'e': 97030,\n",
       "         '؟': 21428,\n",
       "         'ض': 379264,\n",
       "         'ژ': 123819})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object1.dict_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41c50a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars=object1.unique_chars\n",
    "unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67967e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173914876"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chars=object1.all_chars\n",
    "all_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f308340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 0,\n",
       " ' ': 1,\n",
       " 'ب': 2,\n",
       " 'ه': 3,\n",
       " 'گ': 4,\n",
       " 'ز': 5,\n",
       " 'ا': 6,\n",
       " 'ر': 7,\n",
       " 'ش': 8,\n",
       " 'خ': 9,\n",
       " 'ن': 10,\n",
       " 'ح': 11,\n",
       " 'و': 12,\n",
       " 'م': 13,\n",
       " 'ی': 14,\n",
       " 'ث': 15,\n",
       " 'د': 16,\n",
       " 'ف': 17,\n",
       " 'ج': 18,\n",
       " 'س': 19,\n",
       " 'ع': 20,\n",
       " 'ت': 21,\n",
       " 'ل': 22,\n",
       " 'ط': 23,\n",
       " 'ق': 24,\n",
       " 'چ': 25,\n",
       " 'ک': 26,\n",
       " 'پ': 27,\n",
       " '.': 28,\n",
       " 'آ': 29,\n",
       " 'غ': 30,\n",
       " 'N': 31,\n",
       " 'ذ': 32,\n",
       " 'ظ': 33,\n",
       " 'ص': 34,\n",
       " 'e': 35,\n",
       " '؟': 36,\n",
       " 'ض': 37,\n",
       " 'ژ': 38}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index=object1.char2index\n",
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7fdbbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 's',\n",
       " 1: ' ',\n",
       " 2: 'ب',\n",
       " 3: 'ه',\n",
       " 4: 'گ',\n",
       " 5: 'ز',\n",
       " 6: 'ا',\n",
       " 7: 'ر',\n",
       " 8: 'ش',\n",
       " 9: 'خ',\n",
       " 10: 'ن',\n",
       " 11: 'ح',\n",
       " 12: 'و',\n",
       " 13: 'م',\n",
       " 14: 'ی',\n",
       " 15: 'ث',\n",
       " 16: 'د',\n",
       " 17: 'ف',\n",
       " 18: 'ج',\n",
       " 19: 'س',\n",
       " 20: 'ع',\n",
       " 21: 'ت',\n",
       " 22: 'ل',\n",
       " 23: 'ط',\n",
       " 24: 'ق',\n",
       " 25: 'چ',\n",
       " 26: 'ک',\n",
       " 27: 'پ',\n",
       " 28: '.',\n",
       " 29: 'آ',\n",
       " 30: 'غ',\n",
       " 31: 'N',\n",
       " 32: 'ذ',\n",
       " 33: 'ظ',\n",
       " 34: 'ص',\n",
       " 35: 'e',\n",
       " 36: '؟',\n",
       " 37: 'ض',\n",
       " 38: 'ژ'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char=object1.index2char\n",
    "index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8897f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 22, 6, 13]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object1.char_to_index(\"سلام\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a74f1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode=np.array(object1.char_to_index(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "378b64a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174011905"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dae57779",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encode=train_encode[:len(train_encode)//5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95013b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34802381"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21f4db53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'سلام'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object1.index_to_char([19, 22,  6, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "edeb2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('char2index.txt', 'w',encoding=\"utf-8\")\n",
    "for key in char2index.keys():\n",
    "    st=str(key+\" \"+str(char2index[key])+\"\\n\")\n",
    "    file1.write(st)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8049cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('index2char.txt', 'w',encoding=\"utf-8\")\n",
    "for key in index2char.keys():\n",
    "    st=str(str(key)+\" \"+index2char[key]+\"\\n\")\n",
    "    file2.write(st)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e5ebbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test=object1.clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ad94437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from keras.utils import np_utils\n",
    "import math\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a6f5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class define_model(nn.Module):\n",
    "    def __init__(self, n_chars=39, n_hidden=64, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.chars = n_chars\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.chars, n_hidden, n_layers, batch_first=True)\n",
    "        self.lin = nn.Linear(n_hidden, self.chars)\n",
    "        \n",
    "    def forward(self, x, ch):\n",
    "        output, ch = self.lstm(x, ch)\n",
    "        out = output.contiguous().view(-1, self.n_hidden)\n",
    "        out = self.lin(out)\n",
    "        return out, ch\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        c=weight.new(self.n_layers, batch_size, self.n_hidden).zero_()\n",
    "        h=weight.new(self.n_layers, batch_size, self.n_hidden).zero_()\n",
    "        ch = (c,h)\n",
    "        return ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a0d568b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "define_model(\n",
       "  (lstm): LSTM(39, 64, batch_first=True)\n",
       "  (lin): Linear(in_features=64, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=define_model(unique_chars,n_hidden=64,n_layers=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b3acf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_char_LSTM(define_model):\n",
    "    def __init__(self,data,model, epochs, batch_size, seq_length, valid =0.1):\n",
    "        define_model.__init__(self)\n",
    "        self.data=data\n",
    "        self.model=model\n",
    "        self.epochs=epochs\n",
    "        self.batch_size=batch_size\n",
    "        self.seq_length=seq_length\n",
    "        self.valid=valid\n",
    "        self.fit=self.train_char_LSTM_function()\n",
    "\n",
    "    def x_y(self,arr, batch_size, seq_length):\n",
    "        num_batches = len(arr)//(batch_size * seq_length)\n",
    "        arr = arr[:num_batches * (batch_size * seq_length)]\n",
    "        arr = arr.reshape((batch_size, -1))\n",
    "        \n",
    "        for n in range(0, arr.shape[1], seq_length):\n",
    "            x = arr[:, n:n+seq_length]\n",
    "            y = np.zeros(np.shape(x))\n",
    "            y[:,:-1]=x[:,1:]\n",
    "            if(n+seq_length<arr.shape[1]-1):\n",
    "                y[:,-1] =arr[:, n+seq_length]\n",
    "            else:\n",
    "                y[:,-1] = arr[:,0]\n",
    "            yield x, y\n",
    "    def train_char_LSTM_function(self):\n",
    "        self.model.train()\n",
    "\n",
    "        opt = torch.optim.Adam(self.model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        val = int(len(self.data)*(1-self.valid))\n",
    "        data_train, data_val = self.data[:val], self.data[val:]\n",
    "        step = 0\n",
    "        for e in range(self.epochs):\n",
    "            ch = self.model.init_hidden(self.batch_size)\n",
    "\n",
    "            for x,y in self.x_y(data_train, self.batch_size, self.seq_length):\n",
    "                step += 1\n",
    "                    \n",
    "                x = np_utils.to_categorical(x, self.model.chars)\n",
    "                X, Y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                Y = Y.type(torch.LongTensor)\n",
    "                ch = tuple([each.data for each in ch])\n",
    "                \n",
    "                self.model.zero_grad()\n",
    "                output, ch = self.model(X, ch)\n",
    "                loss = criterion(output, Y.view(self.batch_size*self.seq_length))\n",
    "                loss.backward()\n",
    "                    \n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "                opt.step()\n",
    "                if step % 10 == 0:\n",
    "                    val_ch = self.model.init_hidden(self.batch_size)\n",
    "                    val_losses = []\n",
    "                    self.model.eval()\n",
    "                    for x,y in self.x_y(data_val, self.batch_size, self.seq_length):\n",
    "                        X, Y = torch.from_numpy(np_utils.to_categorical(x, self.model.chars)), torch.from_numpy(y)\n",
    "                        Y = Y.type(torch.LongTensor)\n",
    "                        val_ch = tuple([each.data for each in val_ch])\n",
    "                        \n",
    "                        output, val_ch = self.model(X, val_ch)\n",
    "                        val_loss = criterion(output, Y.view(self.batch_size* self.seq_length))\n",
    "                        val_losses.append(val_loss.item())\n",
    "                        \n",
    "                    self.model.train()\n",
    "                    print('Epoch: ',e+1, '    Step: ' ,step, '    Loss: ' ,loss.item(),'    Val Loss: ',np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c337dadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1     Step:  10     Loss:  3.5748071670532227     Val Loss:  3.5678419072689604\n",
      "Epoch:  1     Step:  20     Loss:  3.383718490600586     Val Loss:  3.3467685120572024\n",
      "Epoch:  1     Step:  30     Loss:  2.826709508895874     Val Loss:  2.8421255442489115\n",
      "Epoch:  1     Step:  40     Loss:  2.8102407455444336     Val Loss:  2.7972983724516696\n",
      "Epoch:  1     Step:  50     Loss:  2.763270616531372     Val Loss:  2.772118237625629\n",
      "Epoch:  1     Step:  60     Loss:  2.7994377613067627     Val Loss:  2.7685511112213135\n",
      "Epoch:  1     Step:  70     Loss:  2.7928578853607178     Val Loss:  2.7665173866652033\n",
      "Epoch:  1     Step:  80     Loss:  2.774726629257202     Val Loss:  2.7656276384402907\n",
      "Epoch:  1     Step:  90     Loss:  2.7852818965911865     Val Loss:  2.7631237084575244\n",
      "Epoch:  1     Step:  100     Loss:  2.7549853324890137     Val Loss:  2.7588923170997646\n",
      "Epoch:  1     Step:  110     Loss:  2.756500244140625     Val Loss:  2.757543890238688\n",
      "Epoch:  1     Step:  120     Loss:  2.7415871620178223     Val Loss:  2.7528837791668095\n",
      "Epoch:  1     Step:  130     Loss:  2.7685036659240723     Val Loss:  2.7517832935516244\n",
      "Epoch:  1     Step:  140     Loss:  2.7800939083099365     Val Loss:  2.7450175725226034\n",
      "Epoch:  1     Step:  150     Loss:  2.747159481048584     Val Loss:  2.7407893545073336\n",
      "Epoch:  1     Step:  160     Loss:  2.756606340408325     Val Loss:  2.7363796568444734\n",
      "Epoch:  1     Step:  170     Loss:  2.73238468170166     Val Loss:  2.728605244872315\n",
      "Epoch:  1     Step:  180     Loss:  2.747060775756836     Val Loss:  2.7223833355076636\n",
      "Epoch:  1     Step:  190     Loss:  2.7169950008392334     Val Loss:  2.7164999796455636\n",
      "Epoch:  1     Step:  200     Loss:  2.7185306549072266     Val Loss:  2.7058268552336746\n",
      "Epoch:  1     Step:  210     Loss:  2.7078800201416016     Val Loss:  2.7004938099217153\n",
      "Epoch:  1     Step:  220     Loss:  2.672631025314331     Val Loss:  2.6904761817622447\n",
      "Epoch:  1     Step:  230     Loss:  2.664541006088257     Val Loss:  2.6813113117569927\n",
      "Epoch:  1     Step:  240     Loss:  2.6572272777557373     Val Loss:  2.6723381874746064\n",
      "Epoch:  1     Step:  250     Loss:  2.6353182792663574     Val Loss:  2.6664519353986225\n",
      "Epoch:  1     Step:  260     Loss:  2.632222890853882     Val Loss:  2.65233202438073\n",
      "Epoch:  1     Step:  270     Loss:  2.5692551136016846     Val Loss:  2.6379753672328823\n",
      "Epoch:  1     Step:  280     Loss:  2.6249444484710693     Val Loss:  2.629561756809699\n",
      "Epoch:  1     Step:  290     Loss:  2.542390823364258     Val Loss:  2.6169855110759666\n",
      "Epoch:  1     Step:  300     Loss:  2.5574820041656494     Val Loss:  2.6091038591307467\n",
      "Epoch:  1     Step:  310     Loss:  2.5770022869110107     Val Loss:  2.5992373452415327\n",
      "Epoch:  1     Step:  320     Loss:  2.567361831665039     Val Loss:  2.5911797658983633\n",
      "Epoch:  1     Step:  330     Loss:  2.58610200881958     Val Loss:  2.5828301396317146\n",
      "Epoch:  1     Step:  340     Loss:  2.5921027660369873     Val Loss:  2.5732262134552\n",
      "Epoch:  1     Step:  350     Loss:  2.5444843769073486     Val Loss:  2.566194306440459\n",
      "Epoch:  1     Step:  360     Loss:  2.563279390335083     Val Loss:  2.558097388031738\n",
      "Epoch:  1     Step:  370     Loss:  2.5640861988067627     Val Loss:  2.5528757484196736\n",
      "Epoch:  1     Step:  380     Loss:  2.5613579750061035     Val Loss:  2.5445948764406885\n",
      "Epoch:  1     Step:  390     Loss:  2.5249624252319336     Val Loss:  2.537275072393382\n",
      "Epoch:  1     Step:  400     Loss:  2.4620888233184814     Val Loss:  2.5403201799990947\n",
      "Epoch:  1     Step:  410     Loss:  2.4222066402435303     Val Loss:  2.5292359155042585\n",
      "Epoch:  1     Step:  420     Loss:  2.425585985183716     Val Loss:  2.526878020860172\n",
      "Epoch:  1     Step:  430     Loss:  2.481538772583008     Val Loss:  2.5177316595267545\n",
      "Epoch:  1     Step:  440     Loss:  2.4788219928741455     Val Loss:  2.512219250422122\n",
      "Epoch:  1     Step:  450     Loss:  2.4834158420562744     Val Loss:  2.506748760758291\n",
      "Epoch:  1     Step:  460     Loss:  2.4403178691864014     Val Loss:  2.500839542198885\n",
      "Epoch:  1     Step:  470     Loss:  2.48189640045166     Val Loss:  2.496844254736531\n",
      "Epoch:  1     Step:  480     Loss:  2.4744107723236084     Val Loss:  2.4930356094318125\n",
      "Epoch:  1     Step:  490     Loss:  2.4483776092529297     Val Loss:  2.488541720098235\n",
      "Epoch:  1     Step:  500     Loss:  2.483429431915283     Val Loss:  2.4832469202935474\n",
      "Epoch:  1     Step:  510     Loss:  2.492295265197754     Val Loss:  2.4779806524185237\n",
      "Epoch:  1     Step:  520     Loss:  2.4767796993255615     Val Loss:  2.476574133243068\n",
      "Epoch:  1     Step:  530     Loss:  2.4791436195373535     Val Loss:  2.4738518628687\n",
      "Epoch:  1     Step:  540     Loss:  2.4496986865997314     Val Loss:  2.468010053423498\n",
      "Epoch:  1     Step:  550     Loss:  2.438025712966919     Val Loss:  2.4637102596874167\n",
      "Epoch:  1     Step:  560     Loss:  2.4180259704589844     Val Loss:  2.467247781718349\n",
      "Epoch:  1     Step:  570     Loss:  2.420182704925537     Val Loss:  2.4581664101224106\n",
      "Epoch:  1     Step:  580     Loss:  2.4288876056671143     Val Loss:  2.4602412262525943\n",
      "Epoch:  1     Step:  590     Loss:  2.414973258972168     Val Loss:  2.458889155370283\n",
      "Epoch:  1     Step:  600     Loss:  2.4432432651519775     Val Loss:  2.467400103917421\n",
      "Epoch:  1     Step:  610     Loss:  2.455092668533325     Val Loss:  2.4605450594997054\n",
      "Epoch:  1     Step:  620     Loss:  2.457066059112549     Val Loss:  2.4486466034751975\n",
      "Epoch:  1     Step:  630     Loss:  2.4114878177642822     Val Loss:  2.441722368402235\n",
      "Epoch:  1     Step:  640     Loss:  2.3688912391662598     Val Loss:  2.4463439585977813\n",
      "Epoch:  1     Step:  650     Loss:  2.37821888923645     Val Loss:  2.44240583089005\n",
      "Epoch:  1     Step:  660     Loss:  2.3335366249084473     Val Loss:  2.440162334934812\n",
      "Epoch:  1     Step:  670     Loss:  2.3352413177490234     Val Loss:  2.432032984561146\n",
      "Epoch:  1     Step:  680     Loss:  2.3137705326080322     Val Loss:  2.432297327421688\n",
      "Epoch:  1     Step:  690     Loss:  2.2687530517578125     Val Loss:  2.429264754826732\n",
      "Epoch:  1     Step:  700     Loss:  2.3213083744049072     Val Loss:  2.425019146331562\n",
      "Epoch:  1     Step:  710     Loss:  2.3712384700775146     Val Loss:  2.4208951445083335\n",
      "Epoch:  1     Step:  720     Loss:  2.354999542236328     Val Loss:  2.4196471191420326\n",
      "Epoch:  1     Step:  730     Loss:  2.351663589477539     Val Loss:  2.415832963816794\n",
      "Epoch:  1     Step:  740     Loss:  2.3379993438720703     Val Loss:  2.4160033028943952\n",
      "Epoch:  1     Step:  750     Loss:  2.280060052871704     Val Loss:  2.413818017143165\n",
      "Epoch:  1     Step:  760     Loss:  2.396468162536621     Val Loss:  2.409008415862643\n",
      "Epoch:  1     Step:  770     Loss:  2.432699203491211     Val Loss:  2.4058343255651833\n",
      "Epoch:  1     Step:  780     Loss:  2.379028081893921     Val Loss:  2.4027027529544056\n",
      "Epoch:  1     Step:  790     Loss:  2.3298404216766357     Val Loss:  2.402448146545579\n",
      "Epoch:  1     Step:  800     Loss:  2.3416032791137695     Val Loss:  2.3950625011401865\n",
      "Epoch:  1     Step:  810     Loss:  2.358616828918457     Val Loss:  2.3961248881702493\n",
      "Epoch:  1     Step:  820     Loss:  2.3320038318634033     Val Loss:  2.392582449086038\n",
      "Epoch:  1     Step:  830     Loss:  2.3967761993408203     Val Loss:  2.387825260303117\n",
      "Epoch:  1     Step:  840     Loss:  2.3988687992095947     Val Loss:  2.3867625961444476\n",
      "Epoch:  1     Step:  850     Loss:  2.3501126766204834     Val Loss:  2.383613217800746\n",
      "Epoch:  1     Step:  860     Loss:  2.367537021636963     Val Loss:  2.3808903650164166\n",
      "Epoch:  1     Step:  870     Loss:  2.3250157833099365     Val Loss:  2.381557476036663\n",
      "Epoch:  1     Step:  880     Loss:  2.307093620300293     Val Loss:  2.3784919084218155\n",
      "Epoch:  1     Step:  890     Loss:  2.348041296005249     Val Loss:  2.375039089209919\n",
      "Epoch:  1     Step:  900     Loss:  2.2800300121307373     Val Loss:  2.374407104020629\n",
      "Epoch:  1     Step:  910     Loss:  2.3031516075134277     Val Loss:  2.372702734056874\n",
      "Epoch:  1     Step:  920     Loss:  2.340463161468506     Val Loss:  2.3718448740969724\n",
      "Epoch:  1     Step:  930     Loss:  2.3218512535095215     Val Loss:  2.3644412610803585\n",
      "Epoch:  1     Step:  940     Loss:  2.3390989303588867     Val Loss:  2.363558574796163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1     Step:  950     Loss:  2.318171977996826     Val Loss:  2.363339813872897\n",
      "Epoch:  1     Step:  960     Loss:  2.330045700073242     Val Loss:  2.3582532757762613\n",
      "Epoch:  1     Step:  970     Loss:  2.2981860637664795     Val Loss:  2.3591825152675163\n",
      "Epoch:  1     Step:  980     Loss:  2.3049683570861816     Val Loss:  2.3594690328154617\n",
      "Epoch:  1     Step:  990     Loss:  2.28564453125     Val Loss:  2.356889406253491\n",
      "Epoch:  1     Step:  1000     Loss:  2.3409605026245117     Val Loss:  2.3556800671609124\n",
      "Epoch:  1     Step:  1010     Loss:  2.3219871520996094     Val Loss:  2.35041232566552\n",
      "Epoch:  1     Step:  1020     Loss:  2.333200693130493     Val Loss:  2.349177710684463\n",
      "Epoch:  1     Step:  1030     Loss:  2.231487512588501     Val Loss:  2.3503556840974027\n",
      "Epoch:  1     Step:  1040     Loss:  2.2092602252960205     Val Loss:  2.3490915272068715\n",
      "Epoch:  1     Step:  1050     Loss:  2.226003408432007     Val Loss:  2.3427321198241735\n",
      "Epoch:  1     Step:  1060     Loss:  2.253014326095581     Val Loss:  2.3395258087073745\n",
      "Epoch:  1     Step:  1070     Loss:  2.1622252464294434     Val Loss:  2.33621608023274\n",
      "Epoch:  1     Step:  1080     Loss:  2.173835277557373     Val Loss:  2.3392342729322144\n",
      "Epoch:  1     Step:  1090     Loss:  2.1831676959991455     Val Loss:  2.3329896284645333\n",
      "Epoch:  1     Step:  1100     Loss:  2.164715051651001     Val Loss:  2.328047080233528\n",
      "Epoch:  1     Step:  1110     Loss:  2.2804248332977295     Val Loss:  2.328334201305995\n",
      "Epoch:  1     Step:  1120     Loss:  2.2858073711395264     Val Loss:  2.3260973555575437\n",
      "Epoch:  1     Step:  1130     Loss:  2.2899720668792725     Val Loss:  2.3247802160762774\n",
      "Epoch:  1     Step:  1140     Loss:  2.263470411300659     Val Loss:  2.3239456683507265\n",
      "Epoch:  1     Step:  1150     Loss:  2.2798545360565186     Val Loss:  2.3216654233826923\n",
      "Epoch:  1     Step:  1160     Loss:  2.312171697616577     Val Loss:  2.320503475041407\n",
      "Epoch:  1     Step:  1170     Loss:  2.3155477046966553     Val Loss:  2.319591479987676\n",
      "Epoch:  1     Step:  1180     Loss:  2.29789662361145     Val Loss:  2.3160010624635703\n",
      "Epoch:  1     Step:  1190     Loss:  2.232330799102783     Val Loss:  2.313600327255981\n",
      "Epoch:  1     Step:  1200     Loss:  2.2321465015411377     Val Loss:  2.313590542416731\n",
      "Epoch:  1     Step:  1210     Loss:  2.273425340652466     Val Loss:  2.3078122614054664\n",
      "Epoch:  1     Step:  1220     Loss:  2.274381399154663     Val Loss:  2.308403729512683\n",
      "Epoch:  1     Step:  1230     Loss:  2.2572755813598633     Val Loss:  2.3052375167058403\n",
      "Epoch:  1     Step:  1240     Loss:  2.191652297973633     Val Loss:  2.3077913227996265\n",
      "Epoch:  1     Step:  1250     Loss:  2.2316946983337402     Val Loss:  2.3029191740324575\n",
      "Epoch:  1     Step:  1260     Loss:  2.249777317047119     Val Loss:  2.300930329354487\n",
      "Epoch:  1     Step:  1270     Loss:  2.2390761375427246     Val Loss:  2.300033521828176\n",
      "Epoch:  1     Step:  1280     Loss:  2.270066499710083     Val Loss:  2.2970745545911613\n",
      "Epoch:  1     Step:  1290     Loss:  2.278430700302124     Val Loss:  2.2938909645010184\n",
      "Epoch:  1     Step:  1300     Loss:  2.2559728622436523     Val Loss:  2.2952057241953607\n",
      "Epoch:  1     Step:  1310     Loss:  2.2564432621002197     Val Loss:  2.294186173329934\n",
      "Epoch:  1     Step:  1320     Loss:  2.27828311920166     Val Loss:  2.2928196636073266\n",
      "Epoch:  1     Step:  1330     Loss:  2.291400194168091     Val Loss:  2.291148913302545\n",
      "Epoch:  1     Step:  1340     Loss:  2.2372493743896484     Val Loss:  2.289667498141637\n",
      "Epoch:  1     Step:  1350     Loss:  2.261680841445923     Val Loss:  2.2866219233762735\n",
      "Epoch:  1     Step:  1360     Loss:  2.2678050994873047     Val Loss:  2.2844001780576813\n",
      "Epoch:  1     Step:  1370     Loss:  2.300957441329956     Val Loss:  2.2831279527657147\n",
      "Epoch:  1     Step:  1380     Loss:  2.250527858734131     Val Loss:  2.2830799057034987\n",
      "Epoch:  1     Step:  1390     Loss:  2.227123975753784     Val Loss:  2.27978459759392\n",
      "Epoch:  1     Step:  1400     Loss:  2.2465806007385254     Val Loss:  2.280030913898426\n",
      "Epoch:  1     Step:  1410     Loss:  2.210923910140991     Val Loss:  2.276850896567876\n",
      "Epoch:  1     Step:  1420     Loss:  2.2164552211761475     Val Loss:  2.274912481378365\n",
      "Epoch:  1     Step:  1430     Loss:  2.1649279594421387     Val Loss:  2.2768682852882303\n",
      "Epoch:  1     Step:  1440     Loss:  2.179184675216675     Val Loss:  2.2755636095560785\n",
      "Epoch:  1     Step:  1450     Loss:  2.2006447315216064     Val Loss:  2.271016689244232\n",
      "Epoch:  1     Step:  1460     Loss:  2.2277610301971436     Val Loss:  2.2676906972793636\n",
      "Epoch:  1     Step:  1470     Loss:  2.2084836959838867     Val Loss:  2.269839346628787\n",
      "Epoch:  1     Step:  1480     Loss:  2.206636428833008     Val Loss:  2.2796970381508013\n",
      "Epoch:  1     Step:  1490     Loss:  2.24607515335083     Val Loss:  2.2677125561281324\n",
      "Epoch:  1     Step:  1500     Loss:  2.289036512374878     Val Loss:  2.2672897634471036\n",
      "Epoch:  1     Step:  1510     Loss:  2.1650614738464355     Val Loss:  2.260163358216796\n",
      "Epoch:  1     Step:  1520     Loss:  2.109354019165039     Val Loss:  2.260010728976823\n",
      "Epoch:  1     Step:  1530     Loss:  2.1473159790039062     Val Loss:  2.2578154982675924\n",
      "Epoch:  1     Step:  1540     Loss:  2.1143031120300293     Val Loss:  2.2582878864119413\n",
      "Epoch:  1     Step:  1550     Loss:  2.0874648094177246     Val Loss:  2.256702372948622\n",
      "Epoch:  1     Step:  1560     Loss:  1.9964821338653564     Val Loss:  2.261231031804947\n",
      "Epoch:  1     Step:  1570     Loss:  2.0205936431884766     Val Loss:  2.255237355003498\n",
      "Epoch:  1     Step:  1580     Loss:  2.014685869216919     Val Loss:  2.258227572669842\n",
      "Epoch:  1     Step:  1590     Loss:  2.022352933883667     Val Loss:  2.25306595647467\n",
      "Epoch:  1     Step:  1600     Loss:  2.107813835144043     Val Loss:  2.2553871390564417\n",
      "Epoch:  1     Step:  1610     Loss:  2.163654088973999     Val Loss:  2.2525710751649637\n",
      "Epoch:  1     Step:  1620     Loss:  2.114044427871704     Val Loss:  2.247345695636369\n",
      "Epoch:  1     Step:  1630     Loss:  2.2059667110443115     Val Loss:  2.2474514936609022\n",
      "Epoch:  1     Step:  1640     Loss:  2.1805922985076904     Val Loss:  2.2444054165449527\n",
      "Epoch:  1     Step:  1650     Loss:  2.202307939529419     Val Loss:  2.244580714025181\n",
      "Epoch:  1     Step:  1660     Loss:  2.1067230701446533     Val Loss:  2.2442173896240574\n",
      "Epoch:  1     Step:  1670     Loss:  2.1044387817382812     Val Loss:  2.244751172751958\n",
      "Epoch:  1     Step:  1680     Loss:  2.057237148284912     Val Loss:  2.242364532393283\n",
      "Epoch:  1     Step:  1690     Loss:  2.0792489051818848     Val Loss:  2.2408157125170383\n",
      "Epoch:  1     Step:  1700     Loss:  2.1531717777252197     Val Loss:  2.2385527515763286\n",
      "Epoch:  1     Step:  1710     Loss:  2.1377062797546387     Val Loss:  2.238132368594518\n",
      "Epoch:  1     Step:  1720     Loss:  2.190579891204834     Val Loss:  2.235208061788355\n",
      "Epoch:  1     Step:  1730     Loss:  2.159133195877075     Val Loss:  2.2440737604655023\n",
      "Epoch:  1     Step:  1740     Loss:  2.1684179306030273     Val Loss:  2.23303029633976\n",
      "Epoch:  1     Step:  1750     Loss:  2.2135157585144043     Val Loss:  2.2300352654333926\n",
      "Epoch:  1     Step:  1760     Loss:  2.2120344638824463     Val Loss:  2.2297348738596448\n",
      "Epoch:  1     Step:  1770     Loss:  2.2118430137634277     Val Loss:  2.2313059036142273\n",
      "Epoch:  1     Step:  1780     Loss:  2.224015474319458     Val Loss:  2.2284732375197747\n",
      "Epoch:  1     Step:  1790     Loss:  2.204406976699829     Val Loss:  2.226193209855759\n",
      "Epoch:  1     Step:  1800     Loss:  2.143686532974243     Val Loss:  2.223462091600763\n",
      "Epoch:  1     Step:  1810     Loss:  2.1595652103424072     Val Loss:  2.2258875493193906\n",
      "Epoch:  1     Step:  1820     Loss:  2.2043066024780273     Val Loss:  2.223081915141032\n",
      "Epoch:  1     Step:  1830     Loss:  2.199012279510498     Val Loss:  2.224090240978227\n",
      "Epoch:  1     Step:  1840     Loss:  2.1916306018829346     Val Loss:  2.221608218231764\n",
      "Epoch:  1     Step:  1850     Loss:  2.206489324569702     Val Loss:  2.2192497763686516\n",
      "Epoch:  1     Step:  1860     Loss:  2.2137582302093506     Val Loss:  2.2201910282852904\n",
      "Epoch:  1     Step:  1870     Loss:  2.1973390579223633     Val Loss:  2.21752020441738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1     Step:  1880     Loss:  2.2054712772369385     Val Loss:  2.2171357874500797\n",
      "Epoch:  1     Step:  1890     Loss:  2.207995891571045     Val Loss:  2.2153989837618333\n",
      "Epoch:  1     Step:  1900     Loss:  2.163198947906494     Val Loss:  2.2140541437367234\n",
      "Epoch:  1     Step:  1910     Loss:  2.139845609664917     Val Loss:  2.212789130826718\n",
      "Epoch:  1     Step:  1920     Loss:  2.2220990657806396     Val Loss:  2.215051567422508\n",
      "Epoch:  1     Step:  1930     Loss:  2.209148406982422     Val Loss:  2.2142950248014444\n",
      "Epoch:  1     Step:  1940     Loss:  2.2010626792907715     Val Loss:  2.2114265035439242\n",
      "Epoch:  1     Step:  1950     Loss:  2.170013189315796     Val Loss:  2.213005703753651\n",
      "Epoch:  1     Step:  1960     Loss:  2.1082963943481445     Val Loss:  2.2124297997168507\n",
      "Epoch:  1     Step:  1970     Loss:  2.156310558319092     Val Loss:  2.209234683715989\n",
      "Epoch:  1     Step:  1980     Loss:  2.1371302604675293     Val Loss:  2.2100532732326608\n",
      "Epoch:  1     Step:  1990     Loss:  2.097130060195923     Val Loss:  2.20794194914758\n",
      "Epoch:  1     Step:  2000     Loss:  2.1154799461364746     Val Loss:  2.2058351752502894\n",
      "Epoch:  1     Step:  2010     Loss:  2.171475887298584     Val Loss:  2.2070465580563705\n",
      "Epoch:  1     Step:  2020     Loss:  2.174738883972168     Val Loss:  2.205788608846629\n",
      "Epoch:  1     Step:  2030     Loss:  2.126483917236328     Val Loss:  2.2071589622990233\n",
      "Epoch:  1     Step:  2040     Loss:  2.0897645950317383     Val Loss:  2.2052260861625532\n",
      "Epoch:  1     Step:  2050     Loss:  2.0953257083892822     Val Loss:  2.202139724224696\n",
      "Epoch:  1     Step:  2060     Loss:  2.102032423019409     Val Loss:  2.202095207692952\n",
      "Epoch:  1     Step:  2070     Loss:  2.1358232498168945     Val Loss:  2.199993649971881\n",
      "Epoch:  1     Step:  2080     Loss:  2.146733045578003     Val Loss:  2.1989741923624297\n",
      "Epoch:  1     Step:  2090     Loss:  2.157757520675659     Val Loss:  2.200062769365487\n",
      "Epoch:  1     Step:  2100     Loss:  2.1237361431121826     Val Loss:  2.196975957863445\n",
      "Epoch:  1     Step:  2110     Loss:  2.154470920562744     Val Loss:  2.196104935614385\n",
      "Epoch:  1     Step:  2120     Loss:  2.1050214767456055     Val Loss:  2.197811292106375\n",
      "Epoch:  1     Step:  2130     Loss:  2.0619993209838867     Val Loss:  2.192720615555879\n",
      "Epoch:  1     Step:  2140     Loss:  2.0637354850769043     Val Loss:  2.1944413202715096\n",
      "Epoch:  1     Step:  2150     Loss:  2.0592474937438965     Val Loss:  2.190595404248396\n",
      "Epoch:  1     Step:  2160     Loss:  1.9930517673492432     Val Loss:  2.1880820061447874\n",
      "Epoch:  1     Step:  2170     Loss:  1.9759609699249268     Val Loss:  2.1842245114245538\n",
      "Epoch:  1     Step:  2180     Loss:  2.083838701248169     Val Loss:  2.1882756451399126\n",
      "Epoch:  1     Step:  2190     Loss:  2.096560001373291     Val Loss:  2.1923203547502355\n",
      "Epoch:  1     Step:  2200     Loss:  2.0524721145629883     Val Loss:  2.184143629461197\n",
      "Epoch:  1     Step:  2210     Loss:  1.998331904411316     Val Loss:  2.185209926204048\n",
      "Epoch:  1     Step:  2220     Loss:  2.043785333633423     Val Loss:  2.182639921723257\n",
      "Epoch:  1     Step:  2230     Loss:  2.0283076763153076     Val Loss:  2.1840866289455514\n",
      "Epoch:  1     Step:  2240     Loss:  2.0822558403015137     Val Loss:  2.1803949363117288\n",
      "Epoch:  1     Step:  2250     Loss:  2.144134521484375     Val Loss:  2.1776928479381152\n",
      "Epoch:  1     Step:  2260     Loss:  2.173020839691162     Val Loss:  2.176016919287368\n",
      "Epoch:  1     Step:  2270     Loss:  2.1680452823638916     Val Loss:  2.1765384753251866\n",
      "Epoch:  1     Step:  2280     Loss:  2.17093563079834     Val Loss:  2.178451875039132\n",
      "Epoch:  1     Step:  2290     Loss:  2.138063907623291     Val Loss:  2.177424001517771\n",
      "Epoch:  1     Step:  2300     Loss:  2.0757086277008057     Val Loss:  2.1758005522274004\n",
      "Epoch:  1     Step:  2310     Loss:  2.056260108947754     Val Loss:  2.1742680574255235\n",
      "Epoch:  1     Step:  2320     Loss:  2.0312137603759766     Val Loss:  2.1738999884066987\n",
      "Epoch:  1     Step:  2330     Loss:  2.0486693382263184     Val Loss:  2.170609451308022\n",
      "Epoch:  1     Step:  2340     Loss:  2.106592893600464     Val Loss:  2.170555968126248\n",
      "Epoch:  1     Step:  2350     Loss:  2.099813938140869     Val Loss:  2.172749361868714\n",
      "Epoch:  1     Step:  2360     Loss:  2.049034357070923     Val Loss:  2.170176572025482\n",
      "Epoch:  1     Step:  2370     Loss:  2.0357003211975098     Val Loss:  2.169742783057294\n",
      "Epoch:  1     Step:  2380     Loss:  2.0700058937072754     Val Loss:  2.1677147347988677\n",
      "Epoch:  1     Step:  2390     Loss:  2.0870118141174316     Val Loss:  2.1663108971725973\n",
      "Epoch:  1     Step:  2400     Loss:  2.066211700439453     Val Loss:  2.167570260178119\n",
      "Epoch:  1     Step:  2410     Loss:  2.1295270919799805     Val Loss:  2.1651905577121187\n",
      "Epoch:  1     Step:  2420     Loss:  2.0482780933380127     Val Loss:  2.1629626742148313\n",
      "Epoch:  1     Step:  2430     Loss:  2.040055274963379     Val Loss:  2.1624377785573587\n",
      "Epoch:  1     Step:  2440     Loss:  2.0655200481414795     Val Loss:  2.16046914403289\n",
      "Epoch:  2     Step:  2450     Loss:  2.1183080673217773     Val Loss:  2.160205087098688\n",
      "Epoch:  2     Step:  2460     Loss:  2.143794298171997     Val Loss:  2.1615673457564464\n",
      "Epoch:  2     Step:  2470     Loss:  2.035548448562622     Val Loss:  2.160898476069264\n",
      "Epoch:  2     Step:  2480     Loss:  2.029632806777954     Val Loss:  2.1620667746146225\n",
      "Epoch:  2     Step:  2490     Loss:  2.0631051063537598     Val Loss:  2.1594174708827394\n",
      "Epoch:  2     Step:  2500     Loss:  2.069383144378662     Val Loss:  2.1598569396677054\n",
      "Epoch:  2     Step:  2510     Loss:  2.105883836746216     Val Loss:  2.156846974608643\n",
      "Epoch:  2     Step:  2520     Loss:  2.1523537635803223     Val Loss:  2.1599717263366025\n",
      "Epoch:  2     Step:  2530     Loss:  2.122652053833008     Val Loss:  2.1577544449880115\n",
      "Epoch:  2     Step:  2540     Loss:  2.0923984050750732     Val Loss:  2.1559466682237014\n",
      "Epoch:  2     Step:  2550     Loss:  2.101985216140747     Val Loss:  2.155696622559945\n",
      "Epoch:  2     Step:  2560     Loss:  2.0730860233306885     Val Loss:  2.154238751893554\n",
      "Epoch:  2     Step:  2570     Loss:  2.085678815841675     Val Loss:  2.1534286310751938\n",
      "Epoch:  2     Step:  2580     Loss:  2.1073241233825684     Val Loss:  2.1545716290984207\n",
      "Epoch:  2     Step:  2590     Loss:  2.091984748840332     Val Loss:  2.1527105644620215\n",
      "Epoch:  2     Step:  2600     Loss:  2.1135427951812744     Val Loss:  2.151718621764236\n",
      "Epoch:  2     Step:  2610     Loss:  2.109194278717041     Val Loss:  2.1522334158640506\n",
      "Epoch:  2     Step:  2620     Loss:  2.0719504356384277     Val Loss:  2.1512013027148935\n",
      "Epoch:  2     Step:  2630     Loss:  2.14618182182312     Val Loss:  2.150434308386377\n",
      "Epoch:  2     Step:  2640     Loss:  2.1407511234283447     Val Loss:  2.1478636933428774\n",
      "Epoch:  2     Step:  2650     Loss:  2.1013593673706055     Val Loss:  2.1479837832855564\n",
      "Epoch:  2     Step:  2660     Loss:  2.068079948425293     Val Loss:  2.147116853742142\n",
      "Epoch:  2     Step:  2670     Loss:  2.0658681392669678     Val Loss:  2.14691314222188\n",
      "Epoch:  2     Step:  2680     Loss:  2.0729188919067383     Val Loss:  2.145423623468603\n",
      "Epoch:  2     Step:  2690     Loss:  2.130068063735962     Val Loss:  2.1437352609810354\n",
      "Epoch:  2     Step:  2700     Loss:  2.052994966506958     Val Loss:  2.143374906694757\n",
      "Epoch:  2     Step:  2710     Loss:  1.9625792503356934     Val Loss:  2.141655385274289\n",
      "Epoch:  2     Step:  2720     Loss:  1.9846959114074707     Val Loss:  2.142100701032969\n",
      "Epoch:  2     Step:  2730     Loss:  2.066995143890381     Val Loss:  2.1431331036275605\n",
      "Epoch:  2     Step:  2740     Loss:  1.9832475185394287     Val Loss:  2.1423255359114757\n",
      "Epoch:  2     Step:  2750     Loss:  2.033766984939575     Val Loss:  2.1407007009780714\n",
      "Epoch:  2     Step:  2760     Loss:  2.0584590435028076     Val Loss:  2.1414631389603844\n",
      "Epoch:  2     Step:  2770     Loss:  2.031132698059082     Val Loss:  2.138748822616915\n",
      "Epoch:  2     Step:  2780     Loss:  2.0879745483398438     Val Loss:  2.1401823437961704\n",
      "Epoch:  2     Step:  2790     Loss:  2.124338388442993     Val Loss:  2.1375161976831865\n",
      "Epoch:  2     Step:  2800     Loss:  2.0991621017456055     Val Loss:  2.1383224263842258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2     Step:  2810     Loss:  2.083106756210327     Val Loss:  2.1346280574798584\n",
      "Epoch:  2     Step:  2820     Loss:  2.132993221282959     Val Loss:  2.1355508526312907\n",
      "Epoch:  2     Step:  2830     Loss:  2.1685357093811035     Val Loss:  2.1352944224523003\n",
      "Epoch:  2     Step:  2840     Loss:  2.0115866661071777     Val Loss:  2.134691885036736\n",
      "Epoch:  2     Step:  2850     Loss:  1.9974597692489624     Val Loss:  2.132617625803085\n",
      "Epoch:  2     Step:  2860     Loss:  2.009526252746582     Val Loss:  2.1335798189648845\n",
      "Epoch:  2     Step:  2870     Loss:  2.046086072921753     Val Loss:  2.153644976140828\n",
      "Epoch:  2     Step:  2880     Loss:  2.029420852661133     Val Loss:  2.154466551608265\n",
      "Epoch:  2     Step:  2890     Loss:  2.0297975540161133     Val Loss:  2.1351396518439825\n",
      "Epoch:  2     Step:  2900     Loss:  2.0549521446228027     Val Loss:  2.1366304638640905\n",
      "Epoch:  2     Step:  2910     Loss:  1.9830933809280396     Val Loss:  2.1298450790208205\n",
      "Epoch:  2     Step:  2920     Loss:  2.037038564682007     Val Loss:  2.12849856566679\n",
      "Epoch:  2     Step:  2930     Loss:  2.0797691345214844     Val Loss:  2.1284138144602194\n",
      "Epoch:  2     Step:  2940     Loss:  2.0568225383758545     Val Loss:  2.126687159837392\n",
      "Epoch:  2     Step:  2950     Loss:  2.062227249145508     Val Loss:  2.126243214765598\n",
      "Epoch:  2     Step:  2960     Loss:  2.1232550144195557     Val Loss:  2.123424485160856\n",
      "Epoch:  2     Step:  2970     Loss:  2.120274066925049     Val Loss:  2.122668884777055\n",
      "Epoch:  2     Step:  2980     Loss:  2.062351942062378     Val Loss:  2.122285761076586\n",
      "Epoch:  2     Step:  2990     Loss:  2.0254833698272705     Val Loss:  2.119520376529201\n",
      "Epoch:  2     Step:  3000     Loss:  2.023536205291748     Val Loss:  2.120856052835049\n",
      "Epoch:  2     Step:  3010     Loss:  2.0356154441833496     Val Loss:  2.120249809814115\n",
      "Epoch:  2     Step:  3020     Loss:  2.016134738922119     Val Loss:  2.119372799827604\n",
      "Epoch:  2     Step:  3030     Loss:  2.0833024978637695     Val Loss:  2.118568137123136\n",
      "Epoch:  2     Step:  3040     Loss:  2.0514655113220215     Val Loss:  2.11995062792873\n",
      "Epoch:  2     Step:  3050     Loss:  2.0269832611083984     Val Loss:  2.1168823752456047\n",
      "Epoch:  2     Step:  3060     Loss:  2.1120095252990723     Val Loss:  2.1189147009620806\n",
      "Epoch:  2     Step:  3070     Loss:  2.0704703330993652     Val Loss:  2.1148165301643176\n",
      "Epoch:  2     Step:  3080     Loss:  1.9672863483428955     Val Loss:  2.115091671363014\n",
      "Epoch:  2     Step:  3090     Loss:  2.0202600955963135     Val Loss:  2.1160401787705085\n",
      "Epoch:  2     Step:  3100     Loss:  1.978682518005371     Val Loss:  2.1133301249289427\n",
      "Epoch:  2     Step:  3110     Loss:  1.9598100185394287     Val Loss:  2.1134941393158972\n",
      "Epoch:  2     Step:  3120     Loss:  1.9560637474060059     Val Loss:  2.1138547460971284\n",
      "Epoch:  2     Step:  3130     Loss:  1.9611014127731323     Val Loss:  2.1142865450179884\n",
      "Epoch:  2     Step:  3140     Loss:  1.9653596878051758     Val Loss:  2.113094405494493\n",
      "Epoch:  2     Step:  3150     Loss:  1.9666976928710938     Val Loss:  2.1133587897043826\n",
      "Epoch:  2     Step:  3160     Loss:  2.041398525238037     Val Loss:  2.1113206196535117\n",
      "Epoch:  2     Step:  3170     Loss:  1.9407572746276855     Val Loss:  2.111253327549164\n",
      "Epoch:  2     Step:  3180     Loss:  1.988298773765564     Val Loss:  2.1084548529663647\n",
      "Epoch:  2     Step:  3190     Loss:  1.9744210243225098     Val Loss:  2.107696242877918\n",
      "Epoch:  2     Step:  3200     Loss:  1.9953542947769165     Val Loss:  2.1059465329145595\n",
      "Epoch:  2     Step:  3210     Loss:  2.017214298248291     Val Loss:  2.104960807575071\n",
      "Epoch:  2     Step:  3220     Loss:  2.0463461875915527     Val Loss:  2.1039632114537086\n",
      "Epoch:  2     Step:  3230     Loss:  1.9573206901550293     Val Loss:  2.104768966836683\n",
      "Epoch:  2     Step:  3240     Loss:  1.9484009742736816     Val Loss:  2.102878090200389\n",
      "Epoch:  2     Step:  3250     Loss:  1.9838539361953735     Val Loss:  2.102256949097468\n",
      "Epoch:  2     Step:  3260     Loss:  2.0194015502929688     Val Loss:  2.1028028475842353\n",
      "Epoch:  2     Step:  3270     Loss:  2.002624273300171     Val Loss:  2.1031336669992258\n",
      "Epoch:  2     Step:  3280     Loss:  1.973009467124939     Val Loss:  2.0994796110695138\n",
      "Epoch:  2     Step:  3290     Loss:  2.0179314613342285     Val Loss:  2.098862916341127\n",
      "Epoch:  2     Step:  3300     Loss:  1.9876279830932617     Val Loss:  2.0986840592979066\n",
      "Epoch:  2     Step:  3310     Loss:  2.005309820175171     Val Loss:  2.09897106424029\n",
      "Epoch:  2     Step:  3320     Loss:  1.965301513671875     Val Loss:  2.101076573023497\n",
      "Epoch:  2     Step:  3330     Loss:  1.985808253288269     Val Loss:  2.0983217457563677\n",
      "Epoch:  2     Step:  3340     Loss:  2.029344081878662     Val Loss:  2.096355669612814\n",
      "Epoch:  2     Step:  3350     Loss:  1.9713963270187378     Val Loss:  2.0966116396703405\n",
      "Epoch:  2     Step:  3360     Loss:  2.0337228775024414     Val Loss:  2.0968384892298286\n",
      "Epoch:  2     Step:  3370     Loss:  1.9742506742477417     Val Loss:  2.097390448475236\n",
      "Epoch:  2     Step:  3380     Loss:  2.0347237586975098     Val Loss:  2.0940663189905595\n",
      "Epoch:  2     Step:  3390     Loss:  2.030130386352539     Val Loss:  2.093897958523233\n",
      "Epoch:  2     Step:  3400     Loss:  1.9837965965270996     Val Loss:  2.094988299471866\n",
      "Epoch:  2     Step:  3410     Loss:  2.005880832672119     Val Loss:  2.0931635553986383\n",
      "Epoch:  2     Step:  3420     Loss:  2.051189661026001     Val Loss:  2.096183524360516\n",
      "Epoch:  2     Step:  3430     Loss:  1.969407320022583     Val Loss:  2.092690340707223\n",
      "Epoch:  2     Step:  3440     Loss:  1.9677852392196655     Val Loss:  2.094263333676046\n",
      "Epoch:  2     Step:  3450     Loss:  2.0563528537750244     Val Loss:  2.089804477797223\n",
      "Epoch:  2     Step:  3460     Loss:  2.0255303382873535     Val Loss:  2.0912796338105992\n",
      "Epoch:  2     Step:  3470     Loss:  2.030158281326294     Val Loss:  2.0929419294934433\n",
      "Epoch:  2     Step:  3480     Loss:  1.9212994575500488     Val Loss:  2.0899063850240953\n",
      "Epoch:  2     Step:  3490     Loss:  1.9231436252593994     Val Loss:  2.0875781981267614\n",
      "Epoch:  2     Step:  3500     Loss:  1.9874773025512695     Val Loss:  2.0870859900083927\n",
      "Epoch:  2     Step:  3510     Loss:  1.9370535612106323     Val Loss:  2.085526054195812\n",
      "Epoch:  2     Step:  3520     Loss:  1.8356118202209473     Val Loss:  2.0870865508639063\n",
      "Epoch:  2     Step:  3530     Loss:  1.8803421258926392     Val Loss:  2.087093491395901\n",
      "Epoch:  2     Step:  3540     Loss:  1.8617582321166992     Val Loss:  2.0841192297390028\n",
      "Epoch:  2     Step:  3550     Loss:  1.9082471132278442     Val Loss:  2.0831229950669066\n",
      "Epoch:  2     Step:  3560     Loss:  1.9322922229766846     Val Loss:  2.084969828049635\n",
      "Epoch:  2     Step:  3570     Loss:  1.9773941040039062     Val Loss:  2.0834930462150996\n",
      "Epoch:  2     Step:  3580     Loss:  1.988876461982727     Val Loss:  2.085336396615004\n",
      "Epoch:  2     Step:  3590     Loss:  2.011777877807617     Val Loss:  2.081921361469255\n",
      "Epoch:  2     Step:  3600     Loss:  1.944386601448059     Val Loss:  2.0803980378647133\n",
      "Epoch:  2     Step:  3610     Loss:  2.0493948459625244     Val Loss:  2.079875873903507\n",
      "Epoch:  2     Step:  3620     Loss:  2.0368192195892334     Val Loss:  2.0800506967460097\n",
      "Epoch:  2     Step:  3630     Loss:  1.9859161376953125     Val Loss:  2.076433592616852\n",
      "Epoch:  2     Step:  3640     Loss:  1.9991074800491333     Val Loss:  2.0751945770094755\n",
      "Epoch:  2     Step:  3650     Loss:  2.0006539821624756     Val Loss:  2.076929526575377\n",
      "Epoch:  2     Step:  3660     Loss:  1.9697363376617432     Val Loss:  2.0758210345827783\n",
      "Epoch:  2     Step:  3670     Loss:  1.9688193798065186     Val Loss:  2.0746888674493205\n",
      "Epoch:  2     Step:  3680     Loss:  1.9857778549194336     Val Loss:  2.0759888698254123\n",
      "Epoch:  2     Step:  3690     Loss:  1.9514268636703491     Val Loss:  2.0762163167510086\n",
      "Epoch:  2     Step:  3700     Loss:  1.977128267288208     Val Loss:  2.0717900168851733\n",
      "Epoch:  2     Step:  3710     Loss:  1.9623324871063232     Val Loss:  2.0708484684849138\n",
      "Epoch:  2     Step:  3720     Loss:  1.9451490640640259     Val Loss:  2.0695099307162295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2     Step:  3730     Loss:  1.9938277006149292     Val Loss:  2.0683054158608414\n",
      "Epoch:  2     Step:  3740     Loss:  2.0107367038726807     Val Loss:  2.0708977903387202\n",
      "Epoch:  2     Step:  3750     Loss:  2.017223358154297     Val Loss:  2.072692651590298\n",
      "Epoch:  2     Step:  3760     Loss:  1.962009072303772     Val Loss:  2.0707427276456487\n",
      "Epoch:  2     Step:  3770     Loss:  2.0024523735046387     Val Loss:  2.069583615253772\n",
      "Epoch:  2     Step:  3780     Loss:  2.042965888977051     Val Loss:  2.069180068054762\n",
      "Epoch:  2     Step:  3790     Loss:  2.000006675720215     Val Loss:  2.06710808875376\n",
      "Epoch:  2     Step:  3800     Loss:  1.9810374975204468     Val Loss:  2.069005717210664\n",
      "Epoch:  2     Step:  3810     Loss:  1.9748188257217407     Val Loss:  2.066271823710621\n",
      "Epoch:  2     Step:  3820     Loss:  2.0284481048583984     Val Loss:  2.067954151392863\n",
      "Epoch:  2     Step:  3830     Loss:  1.9809132814407349     Val Loss:  2.0668240776801023\n",
      "Epoch:  2     Step:  3840     Loss:  1.9660128355026245     Val Loss:  2.062158103798588\n",
      "Epoch:  2     Step:  3850     Loss:  1.9512523412704468     Val Loss:  2.0625787124422645\n",
      "Epoch:  2     Step:  3860     Loss:  1.9285154342651367     Val Loss:  2.061648986436344\n",
      "Epoch:  2     Step:  3870     Loss:  1.9116593599319458     Val Loss:  2.061759489928664\n",
      "Epoch:  2     Step:  3880     Loss:  1.9444994926452637     Val Loss:  2.061469330998804\n",
      "Epoch:  2     Step:  3890     Loss:  1.9268466234207153     Val Loss:  2.059896883049574\n",
      "Epoch:  2     Step:  3900     Loss:  1.9443354606628418     Val Loss:  2.0597113397288584\n",
      "Epoch:  2     Step:  3910     Loss:  1.9264211654663086     Val Loss:  2.0575648946515748\n",
      "Epoch:  2     Step:  3920     Loss:  1.9507098197937012     Val Loss:  2.0572446034843193\n",
      "Epoch:  2     Step:  3930     Loss:  1.9584237337112427     Val Loss:  2.056433247904056\n",
      "Epoch:  2     Step:  3940     Loss:  2.013115882873535     Val Loss:  2.056226633571611\n",
      "Epoch:  2     Step:  3950     Loss:  1.9579511880874634     Val Loss:  2.054967542416055\n",
      "Epoch:  2     Step:  3960     Loss:  1.8788279294967651     Val Loss:  2.0586274514778955\n",
      "Epoch:  2     Step:  3970     Loss:  1.8314203023910522     Val Loss:  2.0541875397587175\n",
      "Epoch:  2     Step:  3980     Loss:  1.9063318967819214     Val Loss:  2.0545121682086114\n",
      "Epoch:  2     Step:  3990     Loss:  1.8850610256195068     Val Loss:  2.0511222668679436\n",
      "Epoch:  2     Step:  4000     Loss:  1.835884690284729     Val Loss:  2.0528490129872004\n",
      "Epoch:  2     Step:  4010     Loss:  1.7952576875686646     Val Loss:  2.05201724930443\n",
      "Epoch:  2     Step:  4020     Loss:  1.8164077997207642     Val Loss:  2.0526287573290047\n",
      "Epoch:  2     Step:  4030     Loss:  1.7959120273590088     Val Loss:  2.049338850587936\n",
      "Epoch:  2     Step:  4040     Loss:  1.811476469039917     Val Loss:  2.049414029420522\n",
      "Epoch:  2     Step:  4050     Loss:  1.8710004091262817     Val Loss:  2.0511595191110983\n",
      "Epoch:  2     Step:  4060     Loss:  1.965275526046753     Val Loss:  2.050986612414962\n",
      "Epoch:  2     Step:  4070     Loss:  1.9249887466430664     Val Loss:  2.047119341213325\n",
      "Epoch:  2     Step:  4080     Loss:  1.901313304901123     Val Loss:  2.0471673504452865\n",
      "Epoch:  2     Step:  4090     Loss:  1.9955053329467773     Val Loss:  2.0453408916937907\n",
      "Epoch:  2     Step:  4100     Loss:  1.897534966468811     Val Loss:  2.045800825766532\n",
      "Epoch:  2     Step:  4110     Loss:  1.8907113075256348     Val Loss:  2.0481014524438725\n",
      "Epoch:  2     Step:  4120     Loss:  1.8338723182678223     Val Loss:  2.046991174511364\n",
      "Epoch:  2     Step:  4130     Loss:  1.8718303442001343     Val Loss:  2.0452405860943106\n",
      "Epoch:  2     Step:  4140     Loss:  1.913772463798523     Val Loss:  2.0443390511058794\n",
      "Epoch:  2     Step:  4150     Loss:  1.897400975227356     Val Loss:  2.0429257352413726\n",
      "Epoch:  2     Step:  4160     Loss:  1.9250582456588745     Val Loss:  2.041622735917348\n",
      "Epoch:  2     Step:  4170     Loss:  1.9053529500961304     Val Loss:  2.042646370690687\n",
      "Epoch:  2     Step:  4180     Loss:  1.9362484216690063     Val Loss:  2.042183818412443\n",
      "Epoch:  2     Step:  4190     Loss:  1.956333875656128     Val Loss:  2.041143235245314\n",
      "Epoch:  2     Step:  4200     Loss:  1.9821593761444092     Val Loss:  2.0395758662276604\n",
      "Epoch:  2     Step:  4210     Loss:  2.0191586017608643     Val Loss:  2.038883950437567\n",
      "Epoch:  2     Step:  4220     Loss:  1.9817816019058228     Val Loss:  2.036635817636863\n",
      "Epoch:  2     Step:  4230     Loss:  1.9308847188949585     Val Loss:  2.0373249124336947\n",
      "Epoch:  2     Step:  4240     Loss:  1.9654110670089722     Val Loss:  2.035943207265706\n",
      "Epoch:  2     Step:  4250     Loss:  1.9568699598312378     Val Loss:  2.0354464995465156\n",
      "Epoch:  2     Step:  4260     Loss:  1.967699408531189     Val Loss:  2.0352143612295057\n",
      "Epoch:  2     Step:  4270     Loss:  1.9770501852035522     Val Loss:  2.0342234681013327\n",
      "Epoch:  2     Step:  4280     Loss:  1.975841999053955     Val Loss:  2.031859670178037\n",
      "Epoch:  2     Step:  4290     Loss:  1.9876540899276733     Val Loss:  2.034484745831507\n",
      "Epoch:  2     Step:  4300     Loss:  1.9894565343856812     Val Loss:  2.0312173111412357\n",
      "Epoch:  2     Step:  4310     Loss:  1.933174729347229     Val Loss:  2.0303707122802734\n",
      "Epoch:  2     Step:  4320     Loss:  1.9964271783828735     Val Loss:  2.0335978146408755\n",
      "Epoch:  2     Step:  4330     Loss:  1.9371451139450073     Val Loss:  2.0310835477610794\n",
      "Epoch:  2     Step:  4340     Loss:  1.9299277067184448     Val Loss:  2.030415599636486\n",
      "Epoch:  2     Step:  4350     Loss:  1.8655586242675781     Val Loss:  2.029582174061849\n",
      "Epoch:  2     Step:  4360     Loss:  1.9558568000793457     Val Loss:  2.029217745105279\n",
      "Epoch:  2     Step:  4370     Loss:  1.9606270790100098     Val Loss:  2.027572887410097\n",
      "Epoch:  2     Step:  4380     Loss:  2.0007224082946777     Val Loss:  2.02878448971963\n",
      "Epoch:  2     Step:  4390     Loss:  1.98871648311615     Val Loss:  2.026017601639582\n",
      "Epoch:  2     Step:  4400     Loss:  2.0126683712005615     Val Loss:  2.028560699132096\n",
      "Epoch:  2     Step:  4410     Loss:  1.8449888229370117     Val Loss:  2.0276662960263634\n",
      "Epoch:  2     Step:  4420     Loss:  1.9085267782211304     Val Loss:  2.028288490657877\n",
      "Epoch:  2     Step:  4430     Loss:  1.9309031963348389     Val Loss:  2.0255671255702903\n",
      "Epoch:  2     Step:  4440     Loss:  1.914912223815918     Val Loss:  2.0241360721552946\n",
      "Epoch:  2     Step:  4450     Loss:  1.9430270195007324     Val Loss:  2.0245638223591764\n",
      "Epoch:  2     Step:  4460     Loss:  1.8658467531204224     Val Loss:  2.0242649527933323\n",
      "Epoch:  2     Step:  4470     Loss:  1.8954585790634155     Val Loss:  2.0251114240871586\n",
      "Epoch:  2     Step:  4480     Loss:  1.87739896774292     Val Loss:  2.023658038065442\n",
      "Epoch:  2     Step:  4490     Loss:  1.869032859802246     Val Loss:  2.0252247076632792\n",
      "Epoch:  2     Step:  4500     Loss:  1.9108411073684692     Val Loss:  2.0234491367621614\n",
      "Epoch:  2     Step:  4510     Loss:  1.9249595403671265     Val Loss:  2.0220618006048166\n",
      "Epoch:  2     Step:  4520     Loss:  1.9717828035354614     Val Loss:  2.021078159888292\n",
      "Epoch:  2     Step:  4530     Loss:  1.90464186668396     Val Loss:  2.0224848114696377\n",
      "Epoch:  2     Step:  4540     Loss:  1.9939751625061035     Val Loss:  2.0186760605921164\n",
      "Epoch:  2     Step:  4550     Loss:  1.8924307823181152     Val Loss:  2.0224334305062945\n",
      "Epoch:  2     Step:  4560     Loss:  1.9607210159301758     Val Loss:  2.0196314245132503\n",
      "Epoch:  2     Step:  4570     Loss:  1.9039884805679321     Val Loss:  2.0186635629717276\n",
      "Epoch:  2     Step:  4580     Loss:  1.920570731163025     Val Loss:  2.014689838754295\n",
      "Epoch:  2     Step:  4590     Loss:  1.8597266674041748     Val Loss:  2.014006765566189\n",
      "Epoch:  2     Step:  4600     Loss:  1.8993828296661377     Val Loss:  2.0136527095773564\n",
      "Epoch:  2     Step:  4610     Loss:  1.7866973876953125     Val Loss:  2.011597034236162\n",
      "Epoch:  2     Step:  4620     Loss:  1.8363913297653198     Val Loss:  2.0124354415274195\n",
      "Epoch:  2     Step:  4630     Loss:  1.8757567405700684     Val Loss:  2.0072963127790784\n",
      "Epoch:  2     Step:  4640     Loss:  1.8124189376831055     Val Loss:  2.0102967842038706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2     Step:  4650     Loss:  1.7785124778747559     Val Loss:  2.0099667152355516\n",
      "Epoch:  2     Step:  4660     Loss:  1.8740698099136353     Val Loss:  2.009033556354002\n",
      "Epoch:  2     Step:  4670     Loss:  1.8727885484695435     Val Loss:  2.007118551493571\n",
      "Epoch:  2     Step:  4680     Loss:  1.8183097839355469     Val Loss:  2.00494027577643\n",
      "Epoch:  2     Step:  4690     Loss:  1.8707143068313599     Val Loss:  2.0058765956836435\n",
      "Epoch:  2     Step:  4700     Loss:  1.94551420211792     Val Loss:  2.003653406656976\n",
      "Epoch:  2     Step:  4710     Loss:  1.9345933198928833     Val Loss:  2.002163544792091\n",
      "Epoch:  2     Step:  4720     Loss:  1.928596019744873     Val Loss:  2.0027623783618322\n",
      "Epoch:  2     Step:  4730     Loss:  1.9825820922851562     Val Loss:  2.003215769120248\n",
      "Epoch:  2     Step:  4740     Loss:  1.9110381603240967     Val Loss:  2.005485419857546\n",
      "Epoch:  2     Step:  4750     Loss:  1.894621729850769     Val Loss:  2.002269489738774\n",
      "Epoch:  2     Step:  4760     Loss:  1.853285551071167     Val Loss:  2.0016854548366307\n",
      "Epoch:  2     Step:  4770     Loss:  1.8707435131072998     Val Loss:  2.0011569859796783\n",
      "Epoch:  2     Step:  4780     Loss:  1.840735912322998     Val Loss:  1.9989270385341011\n",
      "Epoch:  2     Step:  4790     Loss:  1.8878495693206787     Val Loss:  1.9966245845675028\n",
      "Epoch:  2     Step:  4800     Loss:  1.857658863067627     Val Loss:  2.009780366042443\n",
      "Epoch:  2     Step:  4810     Loss:  1.8563841581344604     Val Loss:  2.002500839338971\n",
      "Epoch:  2     Step:  4820     Loss:  1.8916029930114746     Val Loss:  1.999750525309151\n",
      "Epoch:  2     Step:  4830     Loss:  1.8643622398376465     Val Loss:  1.9962403730272806\n",
      "Epoch:  2     Step:  4840     Loss:  1.904238224029541     Val Loss:  1.9961179961137665\n",
      "Epoch:  2     Step:  4850     Loss:  1.9113295078277588     Val Loss:  1.9966064845503917\n",
      "Epoch:  2     Step:  4860     Loss:  1.9481992721557617     Val Loss:  1.9949065407263837\n",
      "Epoch:  2     Step:  4870     Loss:  1.8821810483932495     Val Loss:  1.9922531596848885\n",
      "Epoch:  2     Step:  4880     Loss:  1.8842774629592896     Val Loss:  1.9930358377329978\n",
      "Epoch:  2     Step:  4890     Loss:  1.872279167175293     Val Loss:  1.9915364967501032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_char_LSTM(\n",
       "  (lstm): LSTM(39, 64, batch_first=True)\n",
       "  (lin): Linear(in_features=64, out_features=39, bias=True)\n",
       "  (model): define_model(\n",
       "    (lstm): LSTM(39, 64, batch_first=True)\n",
       "    (lin): Linear(in_features=64, out_features=39, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_length = 200\n",
    "n_epochs = 2\n",
    "train_char_LSTM(train_encode,model,n_epochs, batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "333fc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel():\n",
    "    def __init__(self,model):\n",
    "        self.model=model\n",
    "    \n",
    "    def get_next_states_and_output(self, char, h):\n",
    "        x = np.array([object1.char_to_index(char)])\n",
    "        x = np_utils.to_categorical(x, self.model.chars)\n",
    "        X = torch.from_numpy(x)\n",
    "        h = tuple([each.data for each in h])\n",
    "        h=(h[0][0],h[1][0])\n",
    "        out, h = self.model(X, h)\n",
    "        return out,h\n",
    "    \n",
    "    def convert_prefix_to_hiddens(self,string):\n",
    "        h = self.model.init_hidden(1)\n",
    "        ch1=list(string)[0]\n",
    "        out,h = self.get_next_states_and_output(ch1, h)\n",
    "        for ch in string[1:]:\n",
    "            x = np.array([object1.char_to_index(ch)])\n",
    "            x = np_utils.to_categorical(x, self.model.chars)\n",
    "            X = torch.from_numpy(x)\n",
    "            h = tuple([each.data for each in h])\n",
    "            out, h = self.model(X, h)\n",
    "        return out,h\n",
    "    \n",
    "    def get_probs(self,string):\n",
    "        out,h=self.convert_prefix_to_hiddens(string)\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        return p[0]\n",
    "    \n",
    "    def get_next_char(self,string):\n",
    "        p=self.get_probs(string)\n",
    "        p=p.numpy()\n",
    "        m=np.max(p)\n",
    "        tops=np.where(p == m)\n",
    "        top_ch=np.random.choice(tops[0])\n",
    "        char=object1.index_to_char([int(top_ch)])\n",
    "        return char\n",
    "    \n",
    "    def generate_text(self,string,t):\n",
    "        char=\"\"\n",
    "        while ((char!='e') and (len(string)!=t)) :\n",
    "            char=self.get_next_char(string)\n",
    "            string+=char\n",
    "        if char!='e':\n",
    "            string=string+'e'\n",
    "        return string\n",
    "    \n",
    "    def get_overall_prob(self,jomle):\n",
    "        sum=0\n",
    "        for i in range(len(jomle)-1):\n",
    "            ci=object1.char_to_index(jomle[i+1])\n",
    "            p=self.get_probs(jomle[:i+1])\n",
    "            sum+=math.log(p[ci])\n",
    "        return sum\n",
    "    \n",
    "    def evaluate_per(self,test,t):\n",
    "        perplexity=[]\n",
    "        for st in test:\n",
    "            s=self.generate_text(st[:25],t)\n",
    "            log_li = self.get_overall_prob(s)\n",
    "            n=len(s)\n",
    "            perplexity.append((1/log_li)**(1/n))\n",
    "        return perplexity\n",
    "            \n",
    "    def evaluate_cer(self,test,t):\n",
    "        metric = load_metric(\"cer\")\n",
    "        cer=[]\n",
    "        for st in test:\n",
    "            s=self.generate_text(st[:25],t)\n",
    "            cer.append(metric.compute(predictions=[st],references=[s]))\n",
    "        return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c8bcd387",
   "metadata": {},
   "outputs": [],
   "source": [
    "object2=LanguageModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "66bdeec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2618,  0.2962,  0.2889,  0.7344, -0.5939, -0.6479,  0.4767, -0.1893,\n",
       "          -1.1483,  0.1383,  0.6053, -0.6619,  1.0502,  0.6708,  0.6455, -0.8529,\n",
       "           0.8330, -0.0360, -0.3340, -0.7415, -0.3925,  0.6459,  0.0709,  0.4111,\n",
       "          -0.7946, -1.1396, -0.3351, -0.2421, -0.6508, -1.8842, -0.4465, -1.5834,\n",
       "          -0.8201, -0.7242, -0.6079,  0.3743, -0.5391, -0.5540, -0.7621]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " (tensor([[ 0.1239,  0.1934,  0.1039, -0.0050, -0.0463, -0.1453, -0.0010, -0.3334,\n",
       "           -0.0445, -0.2544, -0.2948, -0.2470, -0.1530, -0.2130, -0.0070, -0.1014,\n",
       "            0.0195,  0.0890, -0.0058, -0.0936, -0.0923, -0.2085,  0.0559, -0.1162,\n",
       "            0.2006,  0.1026,  0.0582,  0.1640,  0.0224,  0.2214,  0.0591,  0.3246,\n",
       "           -0.1899, -0.1614,  0.2694, -0.0749,  0.0246,  0.0483, -0.1896, -0.3714,\n",
       "           -0.0973, -0.1411, -0.0712, -0.1289, -0.0063,  0.0758,  0.1837,  0.0367,\n",
       "            0.0779,  0.0579,  0.1554,  0.3491, -0.1090,  0.1337,  0.2253, -0.0987,\n",
       "           -0.1683, -0.1426, -0.0132, -0.0134, -0.0060, -0.1981, -0.0636,  0.0363]],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([[ 0.3562,  0.2445,  0.1626, -0.0077, -0.4059, -0.2206, -0.0082, -0.4972,\n",
       "           -0.1652, -0.4928, -0.7088, -0.4022, -0.1714, -0.5983, -0.0082, -0.5843,\n",
       "            0.0804,  0.5818, -0.0309, -0.1677, -0.1575, -0.3749,  0.3151, -0.2011,\n",
       "            0.3942,  0.3423,  0.2522,  0.2228,  0.0958,  0.5476,  0.1428,  0.5000,\n",
       "           -0.2702, -0.6899,  0.3784, -0.0881,  0.0559,  0.1100, -0.2413, -0.5176,\n",
       "           -0.2209, -0.1786, -0.0799, -0.1597, -0.0372,  0.2717,  0.6716,  0.1784,\n",
       "            0.1854,  0.1025,  0.2805,  0.4126, -0.2230,  0.1677,  0.3583, -0.2794,\n",
       "           -0.2565, -0.4220, -0.0946, -0.0324, -0.0078, -0.3835, -0.0722,  0.2207]],\n",
       "         grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.init_hidden(1)\n",
    "object2.get_next_states_and_output('س',h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3cddb8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.8498,  1.3883,  0.1345,  0.4400,  1.2954, -1.8405,  3.1859, -1.0102,\n",
       "          -0.3491,  0.4257,  1.3518, -0.2608,  0.5192,  0.0740,  0.8325, -1.9273,\n",
       "           0.8334,  0.5140, -0.6390, -0.1142, -2.3563, -0.8019, -3.2859, -1.7468,\n",
       "          -0.6209, -1.4269, -1.6669, -1.2473, -0.8623, -0.0334, -1.7170, -2.1268,\n",
       "          -2.7260, -3.1840, -1.2307, -1.9931, -0.9225,  0.2777, -0.3095]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " (tensor([[-0.2361,  0.2979, -0.1761, -0.3015, -0.0339,  0.0682,  0.1516, -0.3534,\n",
       "           -0.0465,  0.0832, -0.2580, -0.5557, -0.1383,  0.3935,  0.2188,  0.0253,\n",
       "           -0.3899,  0.2730, -0.3552, -0.3162,  0.1453,  0.4416, -0.0137,  0.6815,\n",
       "           -0.3440,  0.3138,  0.0282,  0.4383,  0.0462,  0.2739,  0.1025,  0.1225,\n",
       "           -0.3782, -0.1679,  0.1281, -0.5005, -0.0223,  0.0855, -0.0965, -0.1659,\n",
       "            0.1086, -0.0272,  0.2630,  0.2025, -0.3907,  0.3526, -0.1661,  0.1332,\n",
       "           -0.0096, -0.0536, -0.0014,  0.2942,  0.1885,  0.0368,  0.1372, -0.3881,\n",
       "           -0.1620,  0.0273,  0.3787, -0.0978, -0.0628, -0.3491, -0.5805,  0.3488]],\n",
       "         grad_fn=<SqueezeBackward1>),\n",
       "  tensor([[-0.3751,  0.5657, -0.4945, -0.4298, -0.0753,  0.3978,  0.4595, -0.4927,\n",
       "           -0.0742,  0.1569, -0.5067, -0.8846, -0.2128,  0.6476,  0.2314,  0.0899,\n",
       "           -0.7778,  0.6129, -0.3741, -0.5703,  0.2391,  0.7780, -0.0201,  1.1434,\n",
       "           -0.4087,  0.9375,  0.2002,  1.5960,  0.1521,  0.3167,  0.3646,  1.4226,\n",
       "           -0.7741, -0.5178,  0.1400, -0.8779, -0.0248,  0.1476, -0.6868, -0.1870,\n",
       "            0.4140, -0.2325,  0.2773,  0.3064, -0.9379,  0.4950, -0.2162,  0.4834,\n",
       "           -0.1206, -0.0569, -0.0117,  0.3698,  0.3033,  0.3886,  0.4773, -0.6115,\n",
       "           -0.7470,  0.0365,  0.4202, -0.3170, -0.1373, -1.0015, -0.8055,  0.4093]],\n",
       "         grad_fn=<SqueezeBackward1>)))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.convert_prefix_to_hiddens('خبر')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1f917ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0009, 0.0126, 0.0412, 0.0423, 0.0082, 0.0976, 0.0049, 0.0206, 0.0185,\n",
       "        0.0075, 0.0904, 0.0167, 0.0398, 0.1794, 0.0238, 0.0069, 0.1058, 0.0768,\n",
       "        0.0061, 0.0500, 0.0185, 0.0157, 0.0173, 0.0080, 0.0202, 0.0072, 0.0208,\n",
       "        0.0098, 0.0003, 0.0030, 0.0092, 0.0022, 0.0017, 0.0027, 0.0028, 0.0010,\n",
       "        0.0016, 0.0040, 0.0038])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_probs('سلا')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7f8107dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2865e-07, 3.5305e-01, 2.9995e-02, 1.3400e-03, 7.7936e-03, 4.4035e-04,\n",
       "        1.2312e-01, 7.7260e-02, 7.5201e-03, 2.6684e-03, 1.4166e-01, 1.3496e-03,\n",
       "        1.8029e-02, 3.4449e-02, 6.2117e-03, 9.1722e-04, 1.1950e-01, 2.7329e-03,\n",
       "        3.1842e-03, 1.2941e-02, 7.9020e-04, 5.5540e-03, 2.6035e-02, 6.5666e-03,\n",
       "        4.2592e-03, 1.2096e-03, 4.1886e-03, 5.1277e-04, 1.0644e-03, 5.7085e-04,\n",
       "        3.2656e-04, 3.1647e-05, 1.8485e-04, 1.9667e-04, 2.0411e-03, 1.3440e-04,\n",
       "        1.5619e-04, 1.6089e-04, 1.8515e-03])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_probs('به نقل از برخی')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "583ad887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5148e-06, 9.4167e-01, 1.1249e-03, 3.9070e-03, 1.5269e-03, 2.0151e-03,\n",
       "        7.2664e-03, 3.6727e-03, 4.2653e-03, 1.7606e-05, 1.1338e-02, 1.5287e-05,\n",
       "        1.4185e-03, 1.4213e-03, 9.6226e-03, 4.1220e-04, 1.9859e-03, 5.8200e-05,\n",
       "        3.0333e-04, 1.6511e-03, 1.2145e-05, 2.5430e-03, 7.1499e-04, 2.1689e-06,\n",
       "        5.9694e-05, 3.1474e-04, 3.1381e-04, 4.1492e-05, 1.6529e-03, 1.1092e-05,\n",
       "        1.1880e-05, 3.2788e-06, 2.4236e-05, 3.1695e-06, 1.1099e-06, 1.6137e-05,\n",
       "        5.4827e-04, 2.7151e-05, 5.4928e-06])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_probs('گروه فرهنگی')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "22f0935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'م'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_next_char('سلا')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "999ef17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ر'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_next_char('به گزارش خب')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b3a81654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ه'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_next_char('گروه فرهنگی باشگا')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8852c9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'به گزارش به گزارش خبرنگار خبرنe'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.generate_text('به گزارش',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3888b2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'گروه فرهنگی باشگاه خبرنگاران جوان                 e'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.generate_text('گروه فرهنگی',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "43f63bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'هنرمند پیشکسوت و فرهنگ        e'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.generate_text('هنرمند پیشکسوت و فر',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "47e72aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.085223840054648"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_overall_prob('گزارش')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ce2937ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-76.88412112928302"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_overall_prob('یکی از قوانین حقوق بشر آزادی بیان است')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "656956e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-146.37933382628955"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.get_overall_prob('از ویژگی های بارز این دوره از جشنواره حضور هنرمندان همدانی در بخش داوری و بازبینی آثار است')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e0c44d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9257022583119154+0.057095360962304026j),\n",
       " (0.9175506224774355+0.05659258527365916j),\n",
       " (0.9150138132101682+0.05643612023373231j),\n",
       " (0.9326044354511496+0.05752107267646682j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.919086459853511+0.05668731248057592j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9316788050126793+0.057463981745200725j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9119449813369093+0.056246841162667j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9327251581041547+0.057528518594836105j),\n",
       " (0.9153625452532311+0.05645762928990995j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.912201921023886+0.056262688660112053j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.9210440003425638+0.056808049445207086j),\n",
       " (0.9154482069741913+0.05646291272401088j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.9178247638719123+0.05660949373610679j),\n",
       " (0.9150603587516707+0.05643899106446585j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9163550194011232+0.05651884300005362j),\n",
       " (0.9160506841769325+0.05650007224593404j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.9334441955705574+0.05757286730774143j),\n",
       " (0.927106240689373+0.05718195563127656j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9139661354564844+0.056371501681728525j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9170636915033095+0.056562552399177304j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9231236964125836+0.05693632070817905j),\n",
       " (0.9170478994321024+0.056561578377565265j),\n",
       " (0.9125884471836156+0.05628652877761525j),\n",
       " (0.9177586226013247+0.05660541428217353j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9239459236447519+0.05698703394798392j),\n",
       " (0.9131417399955306+0.056320654710149694j),\n",
       " (0.9312810831103693+0.057439451097931464j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.915445975763516+0.05646277510764694j),\n",
       " (0.9106986296433213+0.05616996882148772j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9231236964125836+0.05693632070817905j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.9165824874008064+0.05653287274604665j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9125189737006395+0.05628224379985679j),\n",
       " (0.9208680595571042+0.056797197789003794j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9312810831103693+0.057439451097931464j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9205486468407905+0.05677749708700148j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9274473988924119+0.05720299754899131j),\n",
       " (0.9216814106140638+0.056847363565061065j),\n",
       " (0.9312810831103693+0.057439451097931464j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9146323151500901+0.05641259023880036j),\n",
       " (0.9279056044057922+0.05723125869769919j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9273200368499476+0.05719514212709718j),\n",
       " (0.9173388691648504+0.0565795247763897j),\n",
       " (0.9243622525740248+0.05701271223739334j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9218358441500836+0.05685688869952472j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.9326044354511496+0.05752107267646682j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9161048492751765+0.056503413034841105j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.9178206674752792+0.056609241079010726j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.9115276628452524+0.056221101839138886j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9203341545569207+0.05676426765576566j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9152772144280851+0.056452366264764256j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9227236343987045+0.05691164572776862j),\n",
       " (0.9259464431726347+0.057110421768993336j),\n",
       " (0.9169708432827776+0.05655682571695483j),\n",
       " (0.9287308636468452+0.05728215894541093j),\n",
       " (0.9308237359664278+0.057411242891638396j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9140754493029108+0.05637824392899416j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9241068714033945+0.05699696086594622j),\n",
       " (0.9326044354511496+0.05752107267646682j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9364320736577504+0.057757153320190754j),\n",
       " (0.9185319878267089+0.05665311381655678j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.9279097466573464+0.057231514183029984j),\n",
       " (0.9261037621281352+0.05712012487003891j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9178846737951482+0.05661318885369094j),\n",
       " (0.9316788050126793+0.057463981745200725j),\n",
       " (0.9279097466573464+0.057231514183029984j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9364320736577504+0.057757153320190754j),\n",
       " (0.9131647544293571+0.05632207419184034j),\n",
       " (0.9273200368499476+0.05719514212709718j),\n",
       " (0.9204359423149889+0.056770545709790336j),\n",
       " (0.9267414720193283+0.057159457469803006j),\n",
       " (0.9165998882412285+0.05653394599314747j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.9256798228474417+0.05709397719022074j),\n",
       " (0.915717250157195+0.05647950673953813j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9181641177173797+0.056630424364855866j),\n",
       " (0.9138368616892929+0.05636352834868922j),\n",
       " (0.91653058849845+0.056529671731317586j),\n",
       " (0.9152325111451155+0.05644960906064767j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9364320736577504+0.057757153320190754j),\n",
       " (0.9165845670647098+0.05653300101532566j),\n",
       " (0.9195210735274019+0.05671411853443086j),\n",
       " (0.921721883599249+0.056849859853341254j),\n",
       " (0.9293337495105735+0.05731934367268102j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9142931393029716+0.056391670588613656j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9259873389829405+0.0571129441362343j),\n",
       " (0.9273200368499476+0.05719514212709718j),\n",
       " (0.920100729754163+0.056749870506734926j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9282378181885779+0.057251748942456056j),\n",
       " (0.9296888401970769+0.05734124491656179j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9169839117344627+0.056557631751464825j),\n",
       " (0.9200981079330977+0.05674970879834677j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9273200368499476+0.05719514212709718j),\n",
       " (0.9223495522590426+0.05688857313115154j),\n",
       " (0.9155672579702101+0.05647025553810643j),\n",
       " (0.9121191632891802+0.05625758433775243j),\n",
       " (0.9165932501794216+0.056533536571509405j),\n",
       " (0.9194777575799654+0.05671144689824104j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9296923853350656+0.057341463573188485j),\n",
       " (0.915731237903466+0.056480369474197385j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.928877924164057+0.05729122932764034j),\n",
       " (0.9274473988924119+0.05720299754899131j),\n",
       " (0.9299071778625532+0.05735471152281677j),\n",
       " (0.9290222770090019+0.05730013270636072j),\n",
       " (0.9274473988924119+0.05720299754899131j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9312810831103693+0.057439451097931464j),\n",
       " (0.913399438556668+0.05633654901335086j),\n",
       " (0.9295473632676836+0.05733251891824103j),\n",
       " (0.9296923853350656+0.057341463573188485j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9279097466573464+0.057231514183029984j),\n",
       " (0.9135295892511456+0.056344576433413805j),\n",
       " (0.9249837932546373+0.057051047554385045j),\n",
       " (0.9241068714033945+0.05699696086594622j),\n",
       " (0.9279097466573464+0.057231514183029984j),\n",
       " (0.9144473737466547+0.056401183443482314j),\n",
       " (0.9133646005833203+0.05633440028070424j),\n",
       " (0.9279056044057922+0.05723125869769919j),\n",
       " (0.9368869814437181+0.05778521107203394j),\n",
       " (0.9235998566740304+0.05696568926784184j),\n",
       " (0.926633341728553+0.057152788221751225j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9282084401433651+0.05724993696664988j),\n",
       " (0.9184992397714181+0.056651093985643705j),\n",
       " (0.9269166822070979+0.0571702640642832j),\n",
       " (0.9267414720193283+0.057159457469803006j),\n",
       " (0.9142799336439055+0.05639085609144207j),\n",
       " (0.9238698690550844+0.056982343061458676j),\n",
       " (0.9274473988924119+0.05720299754899131j),\n",
       " (0.9317837382773659+0.05747045380743287j),\n",
       " (0.9162532166474495+0.05651256402113166j),\n",
       " (0.9381521571674787+0.057863244439653225j),\n",
       " (0.9231236964125836+0.05693632070817905j),\n",
       " (0.9381521571674787+0.057863244439653225j)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.evaluate_per(cleaned_test[\"text\"][:200],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1925dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Melika\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\cer\\46482e3826224451c26c9b51d8d193d38a4226daab693df497d2e397b623274e (last modified on Sat May 28 01:13:19 2022) since it couldn't be found locally at cer, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[22.288888888888888,\n",
       " 24.93548387096774,\n",
       " 21.94,\n",
       " 46.977777777777774,\n",
       " 197.11764705882354,\n",
       " 41.111111111111114,\n",
       " 19.5,\n",
       " 189.63333333333333,\n",
       " 72.5,\n",
       " 14.877551020408163,\n",
       " 24.705882352941178,\n",
       " 37.78431372549019,\n",
       " 9.78,\n",
       " 5.254901960784314,\n",
       " 14.411764705882353,\n",
       " 18.431372549019606,\n",
       " 33.588235294117645,\n",
       " 32.80392156862745,\n",
       " 14.901960784313726,\n",
       " 37.61538461538461,\n",
       " 18.34,\n",
       " 35.76470588235294,\n",
       " 33.16,\n",
       " 15.941176470588236,\n",
       " 58.529411764705884,\n",
       " 62.35294117647059,\n",
       " 41.65217391304348,\n",
       " 56.0,\n",
       " 147.8235294117647,\n",
       " 21.541666666666668,\n",
       " 48.12244897959184,\n",
       " 35.470588235294116,\n",
       " 68.01960784313725,\n",
       " 114.54,\n",
       " 77.2156862745098,\n",
       " 23.313725490196077,\n",
       " 33.205882352941174,\n",
       " 8.254901960784315,\n",
       " 19.92156862745098,\n",
       " 20.06896551724138,\n",
       " 30.08823529411765,\n",
       " 171.80392156862746,\n",
       " 18.333333333333332,\n",
       " 13.88,\n",
       " 53.21739130434783,\n",
       " 18.323529411764707,\n",
       " 10.411764705882353,\n",
       " 152.5686274509804,\n",
       " 14.176470588235293,\n",
       " 6.176470588235294,\n",
       " 6.0588235294117645,\n",
       " 30.98,\n",
       " 27.470588235294116,\n",
       " 90.25490196078431,\n",
       " 188.76470588235293,\n",
       " 46.64705882352941,\n",
       " 18.413793103448278,\n",
       " 24.61764705882353,\n",
       " 33.333333333333336,\n",
       " 36.31372549019608,\n",
       " 107.3921568627451,\n",
       " 26.372549019607842,\n",
       " 16.0625,\n",
       " 14.117647058823529,\n",
       " 17.137254901960784,\n",
       " 568.2156862745098,\n",
       " 38.869565217391305,\n",
       " 11.5,\n",
       " 26.392156862745097,\n",
       " 14.081632653061224,\n",
       " 23.333333333333332,\n",
       " 20.764705882352942,\n",
       " 36.16326530612245,\n",
       " 60.15686274509804,\n",
       " 20.735294117647058,\n",
       " 46.483870967741936,\n",
       " 13.88,\n",
       " 26.58823529411765,\n",
       " 15.294117647058824,\n",
       " 29.555555555555557,\n",
       " 26.686274509803923,\n",
       " 90.5111111111111,\n",
       " 17.441176470588236,\n",
       " 22.916666666666668,\n",
       " 282.4901960784314,\n",
       " 14.666666666666666,\n",
       " 51.888888888888886,\n",
       " 24.529411764705884,\n",
       " 24.45098039215686,\n",
       " 60.1764705882353,\n",
       " 13.566666666666666,\n",
       " 25.676470588235293,\n",
       " 18.529411764705884,\n",
       " 13.019607843137255,\n",
       " 28.235294117647058,\n",
       " 62.30769230769231,\n",
       " 41.189189189189186,\n",
       " 24.13157894736842,\n",
       " 46.69230769230769,\n",
       " 16.84313725490196,\n",
       " 26.352941176470587,\n",
       " 63.24242424242424,\n",
       " 52.73529411764706,\n",
       " 18.266666666666666,\n",
       " 18.955555555555556,\n",
       " 33.26470588235294,\n",
       " 18.568627450980394,\n",
       " 58.34782608695652,\n",
       " 248.05882352941177,\n",
       " 26.647058823529413,\n",
       " 9.27450980392157,\n",
       " 5.980392156862745,\n",
       " 20.147058823529413,\n",
       " 25.419354838709676,\n",
       " 202.73333333333332,\n",
       " 139.58823529411765,\n",
       " 6.803921568627451,\n",
       " 79.93478260869566,\n",
       " 24.96,\n",
       " 22.387096774193548,\n",
       " 38.107142857142854,\n",
       " 191.88235294117646,\n",
       " 47.964285714285715,\n",
       " 38.64705882352941,\n",
       " 45.78431372549019,\n",
       " 55.724137931034484,\n",
       " 11.294117647058824,\n",
       " 11.857142857142858,\n",
       " 13.323529411764707,\n",
       " 54.125,\n",
       " 46.88,\n",
       " 47.529411764705884,\n",
       " 31.794117647058822,\n",
       " 18.41304347826087,\n",
       " 14.857142857142858,\n",
       " 12.72,\n",
       " 28.666666666666668,\n",
       " 58.53846153846154,\n",
       " 28.823529411764707,\n",
       " 17.84313725490196,\n",
       " 42.627450980392155,\n",
       " 18.08823529411765,\n",
       " 41.36,\n",
       " 55.38709677419355,\n",
       " 146.06451612903226,\n",
       " 41.3235294117647,\n",
       " 32.411764705882355,\n",
       " 23.627450980392158,\n",
       " 16.323529411764707,\n",
       " 27.705882352941178,\n",
       " 29.846153846153847,\n",
       " 91.94117647058823,\n",
       " 56.935483870967744,\n",
       " 93.53846153846153,\n",
       " 47.86666666666667,\n",
       " 27.551020408163264,\n",
       " 0.42,\n",
       " 71.55172413793103,\n",
       " 13.333333333333334,\n",
       " 13.511111111111111,\n",
       " 25.771428571428572,\n",
       " 45.450980392156865,\n",
       " 26.92156862745098,\n",
       " 5.235294117647059,\n",
       " 117.33333333333333,\n",
       " 212.8846153846154,\n",
       " 8.235294117647058,\n",
       " 44.94117647058823,\n",
       " 11.264705882352942,\n",
       " 83.72549019607843,\n",
       " 10.653061224489797,\n",
       " 48.42857142857143,\n",
       " 19.68888888888889,\n",
       " 32.01960784313726,\n",
       " 15.470588235294118,\n",
       " 13.980392156862745,\n",
       " 8.725,\n",
       " 49.34,\n",
       " 37.7,\n",
       " 84.11764705882354,\n",
       " 6.18,\n",
       " 37.66,\n",
       " 37.745098039215684,\n",
       " 69.30952380952381,\n",
       " 35.41463414634146,\n",
       " 12.647058823529411,\n",
       " 26.852941176470587,\n",
       " 14.176470588235293,\n",
       " 40.470588235294116,\n",
       " 38.583333333333336,\n",
       " 19.705882352941178,\n",
       " 71.43137254901961,\n",
       " 30.0,\n",
       " 17.49019607843137,\n",
       " 46.90196078431372,\n",
       " 70.4,\n",
       " 49.225,\n",
       " 17.38235294117647,\n",
       " 38.705882352941174,\n",
       " 12.264705882352942]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object2.evaluate_cer(cleaned_test[\"text\"][:200],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b8210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
